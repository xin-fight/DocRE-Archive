# learning from my friends  few-shot personalized conversation systems via social networks(AAAI2021)

现有的个性化对话任务通常需要模型从用户描述或他们的对话历史中提取说话人的偏好，而**这对于新来者和不活跃的用户来说是稀缺的**。

为了更好地迎合资源很少的新来者，我们提出了一种**个性化的对话模式（a personalized conversation model (PCM) ）**，该模式可以学习适应新的演讲者，并使新的演讲者能够**通过社交网络 从资源丰富的演讲者那里学习**（我们的任务不需要对说话者的外部描述 - 年龄，喜好等）

> 特别是，基于基于元学习的PCM，我们提出了一个**任务聚合器（a task aggregator (TA) ）**来**从社交网络中**收集其他说话者的信息。
>
> > 在社交网络中，邻居是互相跟随的用户，他们通常有共同的兴趣和相似的聊天偏好
> >
> > 因此，我们可以利用邻居的对话历史来帮助确定新人的偏好。



**我们首先在大规模的训练集上训练模型；然后对目标演讲者的一些对话进行调整。**

> 但是训练说话者嵌入或构建一个可靠的会话图**需要来自目标说话者的许多样本，而这在我们的设置中并不总是可用的**
>
> 我们做法：
>
> 1. 我们首先构建一个基于MAML的*Personalized Conversation Model*，PCM，其中==每个说话者都作为一个任务。==
>
>    > 1）基于Transformer的说话人独立对话模型（ a speaker-independent conversation model，CM）作为PCM的基础模型：**给定query，确认输出r**
>    >
>    > 2）PCM使用==MAML==来学习使CM适应新的任务（即speakers），从而做出个性化的反应：**可以学习良好的初始参数的CM**，实现快速适应新的speakers
>    >
>    > * ==Model agnostic meta-learning (MAML)== ：能够 **通过学习不同说话者之间的适应能力 来快速适应新的说话者**。然而，**它的目标是成为一个良好的初始模型，满足所有说话者的适应，而不是关心说话者的特点和关系**。由于在建模说话者关系和区分说话者的特征方面的缺陷，这种范式在利用其他资源丰富的说话者时并不有效。
>    >
>    > MAML的训练由内环（ inner-loop）阶段和外环（outer-loop ）阶段组成：
>    >
>    > *  inner-loop：MAML在Ds-sup上训练CM模型
>    > * outer-loop ：MAML根据 由inner-loop阶段训练的模型的性能 来更新参数φ，并在查询集上进行评估
>
> 
>
> 2. 我们提出了一个任务聚合器（TA），根据社交网络中的说话者关系来收集资源丰富的说话者信息。**任务聚合器显式地表示每个任务(i.e. speakers) ，而任务(i.e. speakers) 表示作为新说话者在其元学习中的 先验任务。** 
>
>    > 基于PCM，TA显式地表示具有嵌入的任务：==学习从其他任务（speakers）中聚合嵌入，以细化目标任务（speakers）的表示==
>    >
>    > TA是对任务（speakers）表示 和 任务（speakers）之间的关系进行建模，目的是为PCM提供任务的先验知识
>    >
>    > TA通过**fv Emb获得具有 对话条件的任务嵌入，通过社交网络和任务嵌入聚合器fϕAG细化任务嵌入，然后将细化后的任务嵌入提供给PCM**



我们的任务是**给定一个查询q、一个当前说话者s、说话者支持集Ds sup(所给的K个例子) 和一个社交网络G 来生成响应。**