# BRIO: Bringing Order to Abstractive Summarization

| <font style="background: Aquamarine">exposure bias</font> | <font style="background: Aquamarine"> coordinated：estimate relative quality of different generated outputs</font> | <font style="background: Aquamarine">contrastive learning</font> |
| :-------------------------------------------------------: | :----------------------------------------------------------: | ------------------------------------------------------------ |

​	


>其前置工作是同一作者在21年写的[[SimCLS_A Simple Framework forContrastive Learning of Abstractive Summarization]]
>
>BRIO和SimCLS的主要区别在于**前者使用单一模型(BART)进行候选摘要生成和评分**，而**后者将候选摘要生成(BART)和评分(RoBERTa)采用了两个独立的模型**，这样做的好处在于可以最大化两个阶段的参数共享，即评分模型可以继承生成模型的权重，其他方面如出一辙，都是通过引入基于对比学习的评分模块来对生成模块生成的候选摘要进行评分和排序，从而解决训练时的目标函数(LOSS)和评价指标(ROUGE)不一致的问题。



> 这篇论文其实是从另外一个角度审视了曝光偏差的，在MLE方式下训练时，模型只鼓励将高概率分配给参考摘要，而非参考摘要之间的相对好坏是不能够确定的。但是在推理阶段，模型生成的摘要并不一定是参考摘要，而可能出现很多错误，当我们通过beam search生成多个作为候选摘要的非参考摘要时，模型是没有足够的能力去区分这些生成的多个候选摘要之间的相对好坏的，这是因为我们在训练阶段就没有刻意的去训练模型评价不同候选摘要的能力，**根据生成概率来判断候选摘要的相对好坏是没有足够信服力的，因为那只是模型在采用teacher- force方式下强迫生成参考摘要的余威**。
>
> 总结下来就是说，**在训练时，模型只关注最优的参考摘要而不关注别的可能摘要的相对好坏**；**在推理时**，模型并不能生成最优的参考摘要，而是使用 beam search生成多个候选摘要，而**又要求模型具备有判断候选摘要相对好坏的能力从而能够选出最优的候选摘要**





抽象摘要模型通常使用最大似然估计进行训练，**该方法假设一个确定性（单点）目标分布，理想模型将把所有概率质量分配给参考摘要**。==这种假设可能导致摘要过程中性能下降==。





BRIO模型使用一种新的训练目标，鼓励模型生成多样化和信息丰富的摘要。

> 我们主张做出另一种假设，即**一个候选对象的概率应该 与 自动度量M评估的质量密切相关**





对于***exposure bias***，为了在 有错误的 子序列中保持合理的性能，我们认为该模型必须**准确地估计不同生成输出的相对质量**，因为有效的推断需要在这些候选序列之间进行比较

> 实验发现：由于MLE训练只鼓励模型为参考摘要分配高概率，并且与非参考摘要之间的任何相对比较都没有任何关系，**导致模型并没有为更好的摘要分配更高的概率**
>
> 然而，我们认为，==**coordinated：将模型分数的顺序 与 评估摘要的实际质量指标相协调也很重要**==



我们引入了一个训练范式，它要求抽象模型能够**准确地预测参考摘要中的token，并与候选摘要进行协调**

> | **a dual model**:    | 功能                                                         | loss                         |
> | -------------------- | ------------------------------------------------------------ | ---------------------------- |
> | **generation model** | 自回归方式生成摘要                                           | standard MLE loss            |
> | **evaluation model** | 它可以用来通过估计候选输出上的概率分布来对候选摘要的质量进行评分 | a *contrastive* loss对比损失 |



**我们主要贡献**：将抽象模型的**目标分布从MLE训练假定的一点确定性分布 改变为 非确定性分布**，其中候选摘要也根据其质量分配概率质量；使用我们的方法进行训练，模型可以更准确地估计候选者的摘要质量，



**Beam Search**

> beam宽度增大，可能会导致性能下降
>
> 这种原因是与生成器的**低的 序列级别协调 密切相关**：
>
> * 具体来说，增加光束宽度可能会引入质量较低的候选材料（斯塔尔伯格和Byrne，2019），而生成器可能无法将它们与高质量的候选材料区分开来
> * 但另一方面，**我们的模型能够在更多的光束下获得更好的性能，这表明我们的训练方法可以通过鼓励模型将估计的概率分配给与其质量密切相关的候选摘要来改进模型的协调**



## Related Work

为了调整训练目标和评价度量，在Seq2Seq模型训练中使用了结构化损失。

* 其中，以边缘为基础的损失(margin based losses)要求模型分配较高的概率给较好的输出，是一个主要的类别:

>现代seq2seq模型中使用的许多基于边际的损失都假设了**一个确定性（一点）分布**：如果一个模型能够为（伪）参考分配更高的概率，无论其他候选摘要的相对比较，它可以实现零损失。

* 相比之下，我们的方法具有非确定性假设(Eq。7)，它侧重于对一组候选摘要的两两排序。



## 对比之前该作者提出的*SimCLS*

对比SimCLS， 我们将BRIO-Ctr的优越性能归因于它在**候选生成和评分方面使用了相同的模型体系结构**（BART），而SimCLS则使用RoBERTa作为评估模型。

因此，BRIO-Ctr使两个阶段之间的参数共享最大化，并保留了在同一数据集上预训练的Seq2Seq模型的能力

## 模型

<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230424182556396.png" alt="image-20230424182556396" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230424182619445.png" alt="image-20230424182619445" style="zoom:67%;" />

<hr>
<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230424182152921.png" alt="image-20230424182152921" style="zoom:67%;" />


> 对比损失 被用来训练模型作为无参考评分模型的能力。
>
> 典型的对比学习中的对比损失需要显式的构造正样本和样本，但这里没有采用这种方式，而是**采用排序损失(ranking loss)**来实现对比损失，标题中的Bring Order正源于此。也就是说，论文通过==引入排序损失==这种对比学习方式，来把评价指标M（通常为Rouge）引入到了评分函数，从而让整体模型在训练过程中不再仅仅依赖于token级别的损失，而能够直接拥有[感知序列](https://www.zhihu.com/search?q=感知序列&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"562660923"})级别的差异的能力。对比损失公示如下，

<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230424182229717.png" alt="image-20230424182229717" style="zoom:67%;" />

> 该框架采用的是一个一个多任务损失 ，分别由对 比损失 和普通的 交叉熵损失 构成，由于**对比损失是定义在序列级别**的，所以这里**token级别的交叉熵损失可以起到标准化的辅助作用**，==以确保评分模型可以在整个序列上分配相对平衡的概率==。实际上，直接去除这里的交叉熵损失也不会产生太大的影响，评分模型的关键只在于这个对比损失。

