# Pretrained Language Models for Text Generation A Survey

## Abstract

 three key aspects of applying PLMs to text generation:

>1. 如何将输入编码为能够融入到PLM的保留输入语义的文本表征
>2. 如何设计一个有效的PLM作为生成模型
>3. 如何根据参考文本的有效地优化plm，并确保生成的文本满足特殊的文本属性



## 1. INTRODUCTION

文本生成的主要目标:

> 从数据中自动学习输入到输出的映射，从而以最小的人工干预构建端到端解决方案。这个映射函数允许生成系统在更广泛的领域中泛化，并在给定的条件下生成自由文本。



方法：

> 早期NLG通常采用**统计语言模型**来对给定 **n-gram 上下文的单词的条件概率进行建模**这种方法最主要的问题就是数据稀疏，所以就衍生出来很多平滑算法来缓解未登录词的问题。此外用word tokens是作为基础表示单元，也会导致相似的tokens不能相互映射的问题。
>
> **深度学习技术**出现以后，通常采用**基于encode-decoder的Seq2Seq框架结构建模**，而通过embedding的表征方式也让输入输出关系的处理变得更简单。随着Transfomer模型以及更高的计算能力的涌现，**PLM逐步成为了NLG的主流**。
>
> > 图神经网络（GNN）编码图输入[102]和递归神经网络（RNN）解码文本[108]
> >
> > 注意机制[2]和复制机制[164]被广泛用于提高文本生成模型的性能。
>
> > 深度神经网络用于文本生成的一个重要优点是，它们能够**从输入数据中端到端学习语义映射来输出文本，而不需要进行劳动密集型的特征工程**
> >
> > 此外，深度神经模型采用低维语义表示[82]来捕获语言的语言特征，这有助于缓解数据的稀疏性
>
> > 一个主要的性能瓶颈是大规模标记数据集的可用性。(需要大量标记数据)
> >
> > 现有数据量小，可能会过拟合，并且在实践中不好推广



预训练语言模型（PLMs）的范式在NLP中蓬勃发展：

> **基本思想**是首先在大规模无监督语料库上对模型进行预训练，然后在下游监督任务中进行微调
>
> 大量研究表明，plm可以将**来自训练前语料库的大量语言知识编码到它们的大规模参数中**，并学习用特殊设计的目标学习语言的通用和上下文表示，如masked token预测。



通过三个步骤将PLM应用于文本生成任务（参见图1）：

> input representation learning  输入数据表示学习
>
> model architecture design and selection  模型架构
>
> model parameters optimization  模型参数优化

经过大规模语料库预训练，plm能**准确地理解自然语言**，并能进一步**流利地用人类语言表达**，这两者都是完成文本生成任务的关键能力。



<hr/>

**第2章**中介绍了任务的制定和plm的概述

给定编码的输入数据，文本生成的目标是优化生成函数（即plm），以生成令人满意的输出文本。因此，在将plm应用于文本生成时，涉及到三个关键点：

> 1. 如何将（**第3章**）
>
> 2. 如何设计一个有效的PLM作为生成函数（**第4章**） 
>
>    根据训练前的目标，文本生成的plm可以分为**掩码(masked LMs)、因果码(causal LMs)、前缀(prefix LMs)和编解码器(encoder-decoder LMs)**
>
> 3. 如何优化给定参考文本的plm，并确保生成的文本满足特殊的文本属性（**第5章**）

然后，我们将在**第6章**中的每个关键点中讨论几个典型的非平凡的挑战和解决方案。

我们总结了在**第7章**中使用plm的各种有用资源，在**第8章**中介绍了常见的应用。最后，在**第9章**中描述了未来的发展方向。



## 2 PRELIMINARY - 介绍了任务的定义和PLMs的概述

介绍了**文本生成的一般任务定义**，然后**描述了plm的背景**，最后**介绍了基于PLM的文本生成方法的三个关键方面**。

### 2.1 Text Generation

文本可以建模为标记𝑦=<𝑦1，...，𝑦𝑗，...，𝑦𝑛>序列，其中每个标记𝑦𝑗从词汇表V中提取。

属性集p；文本生成是基于一些输入数据(例如，文本、图像、表格和知识库）x；𝑓M文本生成模型

$𝑦 = f_M (𝑥,P)$



具体地说，根据输入数据𝑥的类型和属性集P，**文本生成可以实例化为不同类型的任务**

> 1. 当没有提供输入数据𝑥或是随机向量时，文本生成将退化为语言建模或无条件文本生成[152,153]。在这种情况下，输出文本需要满足一些常见的语言属性，如流畅性和自然性。
> 2. 当输入数据𝑥是一组离散的属性（例如，主题词和情感标签）时，它就变成了主题到文本的生成[33]或基于属性的生成[90]。输入数据𝑥起着控制生成文本内容的作用。在这种情况下，输出文本应该与输入主题相关或拥有所需的属性。
> 3. 当输入数据𝑥是知识库或表等结构化数据时，它被认为是数据到文本的生成[60,105]。此任务旨在生成关于结构化数据的描述性文本。因此，输出的文本应该是客观和准确的。
> 4. 当输入数据𝑥是图像和语音等多媒体输入时，它成为图像字幕[191]或语音识别[45]。我们可以期望标题文字生动，吸引孩子的注意，转换的语音文本忠实于原始语音。
> 5. 输入数据的最常见的形式是文本序列。这个表单跨越了许多应用程序，如机器翻译[31]、文本摘要[161]和对话框系统[215]。对于特定的任务，输出文本需要满足所期望的属性。例如，文本摘要中的摘要不应该与输入文本中描述的事实相矛盾，而对话框中的响应应该与输入对话框的历史记录和上下文相关。



### 2.2 Pre-trained Language Models

研究表明，plm可以将大量的语言知识编码到其大量的参数中[106,158]

> XLNet、RoBERTa和ERNIE是基于BERT模型开发的，而T5和BART是基于编码器解码器的plm
>
> 最近的研究表明，通过增加模型参数的规模，可以提高的性能[89]，从而引发了大型PLMs（如GPT-3（175B）[14]、PANGU（200B）[207]、GShard（600B）[98]和  Switch-Transformers（1.6T）[46]）的发展
>
> 此外，plm还被设计用于其他任务，如命名实体识别[147]、programming[49]和networking[127]

根据训练前的目标，文本生成的plm可以分为掩码、因果码、前缀和编码解码器，将在第4节中详细介绍



### 2.3 PLM-based Text Generation Methods

为了有效地利用plm用于下游文本生成任务，我们需要分别从**数据、模型和优化**的角度考虑三个关键方面：

> **输入数据：**对于文本生成，输入数据包含目标输出的关键语义信息，通常出现在不同任务的**不同数据类型**中（例如，顺序文本、结构化表、多媒体），**而大多数plm通常是对顺序文本数据进行预先训练的。因此，开发有效的、灵活的表示学习方法来从各种类型的输入数据中捕获语义信息是一个主要的挑战。**
>
> **模型体系结构：**通用架构不能处理一些特殊的文本生成情况。因此，在适应不同的文本生成任务时，对底层plm进行特定的设计，以实现良好的任务性能是很重要的。
>
> **优化算法：**为了生成令人满意的文本，通过开发有效的优化算法来学习文本生成函数是至关重要的。一个主要的挑战是，输出文本的一些期望属性难以制定或优化。



## 3 ENCODING INPUT REPRESENTATIONS - 将数据编码并可以融合到plm中

在本节中，我们将介绍用于文本生成的三种主要输入数据类型，即**非结构化输入、结构化输入和多媒体输入**。

### 3.1 Unstructured Input

**文本表示学习的目的**是==将输入的文本压缩成能够保留核心语义意义的低维向量。==

接下来，我们将讨论如何为三种==非结构化文本数据获得有效的语义表示==，即**段落、文档和多语言文本**。

#### 3.1.1 Paragraph Representation Learning 段落

一个段落通常由多个描述不同主题的句子组成，每个句子包含一系列的单词。为了在段落中**捕获低级单词含义和高级主题语义**，许多研究提出了**基于层次结构或基于图**的方法来学习段落表示。

**Hierarchy-based Representation Learning.** 

> 对于一个多句的段落，如多回合对话，一个典型的方法是**将句子作为一个整体的文本 连接起来**，并预测输出文本 [7, 215]。 
>
> **flat concatenation不能有效地捕获话语之间的语义动态**，这可能会导致不准确的生成。为了解决这个问题，人们提出了分层编码器来对输入段落[64,112]进行建模。
>
> > Gu *et al.* [64]  使用DialogBERT表来表示对话上下文
> >
> > 一个层次框架，利用句子和话语Transformer编码器分别**编码每个对话的话语 和 话语向量的序列**
>
> > 然而，在编码每个单独的话语时，它没有**考虑历史信息**，而这是理解对话话语的必要条件。
> >
> > 改进： Li *et al.* [112] 采用变压器将每个话语编码为一个密集的向量，在此向量上设计了一个从左到右的流模块来捕获话语级的动态信息流。

**Graph-based Representation Learning.**

> 如何利用关键语义并从复杂的段落文本中**删除次要信息**对于提高基于段落的生成性能至关重要。
>
> 与序列相比，通过明确地**将单词或短语表示为节点，并将它们之间的关系（如相似性）表示为边**，图可以很容易地聚合文本[138,190]中相关但不相交的上下文。
>
> > Wu *et al.* [190]利用了短语级统一语义图，**其中节点是通过依赖解析提取的短语，关系是依赖关系**。
> >
> > 这个图可以用于聚合分散在上下文中的共引用短语，以便更好地**捕捉长期关系和全局段落结构**
>
> > 此外，在对话式机器阅读中， Ouyang *et al.* [138] 将输入文本表述为两个互补图，即显式语篇图和隐式语篇图，以充分捕捉 所有基本语篇单元之间的 语篇关系 和 潜在向量交互作用。

#### 3.1.2 Document Representation Learning  文档

在许多文本生成任务中，如文档翻译和文档摘要，输入文本可能是由多个段落组成的长文档。

在对文档进行编码时，**对跨句子（段落）语义进行建模并捕获最关键的语义具有挑战性**

**Modeling Inter-Sentential Semantics. **句间语义的建模

> 大多数plm被训练成掩蔽语言模型。它们主要关注于学习标记级(Token)的表示，而不是句子级的表示。**虽然段嵌入被用于单独表示不同的句子，但它们不能捕获跨句语义。**
>
> 为了编码句间语义，[123,214,222]提出了几项研究，**以分层的方式学习文档表示**。
>
> > Liu *et al.* [123]在**每个句子的开头插入“[CLS]”标记**，将句子级的特征聚合到更低的层次中，然后将它们与更高层次中的自我注意结合起来。
>
> >  Zhang *et al.* [214 ] 提出了一种分层学习文档表示的HIBERT，**使用句子编码器将句子映射到句子向量中**，**使用文档编码器进一步学习上下文敏感的句子表示**，将它们周围的句子向量作为上下文。

**Capturing Critical Semantics.** 捕获关键语义。

> 长文件中的句子或段落将不可避免地相互补充、重叠或冲突。因此，有必要**保留最关键的内容**，并在生成的文本中进行语言表达。
>
> >  Nguyen *et al.* [136] 引入了一个主题模型来捕获文档的全局主题语义 和 一个门机制来控制提供给文本生成模块的全局语义的数量
>
> >  Liu *et al.* [118] 提出了两个主题感知的对比学习目标。其中，**一致性检测目标**：通过检测主题之间的一致性变化来确定对话的主题，而**子摘要生成目标**：迫使模型捕获最显著的信息，并为每个主题生成子摘要。

**Representation Learning Efficiency.** 表示法的学习效率。

> 由于**自注意机制随着序列长度的增加呈二次增长**，许多研究旨在提高自注意的编码效率
>
> > Manakul *et al.* [133] 提出了**局部自注意力**，允许在训练期间有**更长的输入跨度；以及显式内容选择，减少内存和计算需求**
>
> > **分治编码方法**：通过**将长文档分解成短句子**，单独总结文档的每个简短部分更容易[56]，降低了计算复杂度。

#### 3.1.3 Multi-lingual Representation Learning. 多语言

应用基于英语的plm很难解决多语言的文本生成任务

**Cross-lingual Representations.** 跨语言表示。

>跨语言表示学习的**核心思想**是**学习两种语言的共享嵌入空间，以提高plm在它们之间的翻译能力**
>
>> 有名的跨语言的PLM是XLM [31] 它利用**单语言和并行数据**来学习跨语言表示。
>
>> 然而，这些在**共享 字节对编码（BPE）空间上的学习表示是隐式的和有限的**。
>>
>> 因此，Ren等人[157] 进一步计算了**跨语言的𝑛-gram嵌入**，并在此基础上导出了一个𝑛-gram翻译表，用于提供显式表示学习信号。

**Multi-lingual Representations.** 多语言表示。

> 给定两种以上的语言，**多语言plm的目标是学习任何一种语言的表示**。
>
> > Liu等人[122] 和 Xue等人[194] 基于英语plm、BART和T5，分别提出了mBART和mT5，并**对所有语言进行了一次预训练**。
>
> > 考虑到不同语言之间的差异（例如，句法规则），一些研究**利用对比学习来学习多语言表示**[139,185]。
> >
> > Wang等人[185] 特别提出了**两个训练目标：对比句子排名（CSR）和句子对齐替代（SAS）。**CSR根据句子的显著性分数创造积极和消极的句子对，而SAS用另一种语言的句子代替句子
> >
> > **通过在公共文本中对比学习这些语言，该模型可以学习跨语言的共享表示空间。**

### 3.2 Structured Input

结构化数据（例如，表、图和树），**由于三个主要挑战，对plm的结构化输入进行建模是很重要的**：

> (1) 结构化数据和plm之间存在**语义差距**，因为plm通常是对自然语言文本进行预先训练的
>
> (2) 对输入数据中的结构信息进行编码不是简单的；
>
> (3) 需要保持生成的文本相对于输入的保真度

#### 3.2.1 Bridging the Semantic Gap. 弥合语义差距。

一般来说，**plm是在非结构化文本上进行预训练的，这在形式上与结构化数据不同**。已经提出了几种方法来弥补这一差距。

**Structured Data Linearization.** 结构化数据线性化。

> 为了拟合plm的结构化输入，一个简单的方法是**将输入数据线性化为一个序列**[43,130,158]。
>
> > Ribeiro *et al.* [158] 通过**连接关系三元组将知识图（KG）线性化成三元组序列**。
>
> > 此外，一些研究采用了**基于模板的启发式方法**[60]对输入数据进行序列化。

**Representation Alignment.** 表示对齐。

> 语义差距使得在**直接序列化结构化数据时，很难有效地将结构化数据表示注入到plm中**
>
> > 一些人提出将结构化数据表示与语义空间中基于PLM的**单词嵌入对齐**。
> >
> > Li *et al.*  [105]利用图神经网络（GNN）将KG实体投影到嵌入中，然后通过**最小化基于GNN和基于PLM的实体嵌入之间的欧氏距离来执行表示对齐。**

#### 3.2.2 Capturing the Structural Information. 捕获结构性信息

结构信息可以通过**以更准确的方式建模输入来帮助生成忠实的文本**

**Incorporating Additional Training Objectives.** 引入额外的训练目标。

> 为了加强结构信息的保存，一个典型的方法是**引入与结构信息相关的辅助训练目标**[60, 105, 130].
>
> > 其中一种目标是**重构输入数据的语义结构**。
> >
> > Gong *et al.* [60] ]利用输入表的属性名作为标签，**基于plm中的属性值表示来重构表结构**，这将强制plm将表结构嵌入到表的表示中。
>
> > 另一种方法是**根据结构信息来调整输出文本**。
> >
> > Mager *et al.* [130] 提出了**基于周期一致性的损失**，以根据 *输出文本重构输入结构* 的能力来评估输出文本的质量。

**Adding Structural Information as Input.**  添加结构性信息作为输入。

> 与之前的训练损失隐含捕获结构信息的研究相反，一些研究**明确地将结构信息作为输入**[43,158]。
>
> > Ribeiro *et al.* [158] 在KG三重的头实体、关系和尾实体之前直接**添加“〈H〉”, “〈R〉”, and “〈T〉” 标记**，以揭示实体之间的关系。
>
> > Fan *et al.* [43]  使用**抽象意义表示（AMR）图**的图嵌入作为输入；图嵌入**通过编码每个节点的深度（从节点到根节点）和每个节点所属的子图**来提供图的结构信息。

**Employing Structural Encoding Module.** 采用结构性编码模块。

> 由于plm最初是为顺序输入而开发的，因此**合并额外的模块来编码结构化输入**是有意义的。
>
> > 一个典型的例子是 StructAdapt[159]，它添加了**层级图卷积模块**来学习建立在PLM编码器上的图连通性上的表示
>
> > Li *et al.* [105] 采用**GNN将KG关系编码为嵌入**，作为plm的输入。

#### 3.2.3 Maintaining Text Fidelity. 维护文本保真度

保真度是指生成的文本附着于结构化数据中的内容；生成能够正确**描述结构化输入信息的高保真文本**是数据到文本生成算法的关键。

**Incorporating Additional Training Objectives.** 引入额外的训练目标。

> > Gong *et al.* [60]  引入了一个**基于最优传输的内容匹配损失**，它度量输入信息和输出文本之间的距离
>
> > Harkous *et al.* [72] 采用**语义保真度分类损失**来检测和避免生成错误，如幻觉(hallucination)。

**Utilizing Copy Mechanism.** 利用复制机制。

> > 指针生成器(pointer-generator)[164]是一种典型的方法，通过**将重要的单词从输入中复制到输出中，来确保生成的文本对输入数据的忠实性。**
>
> > Li *et al.* [105] 采用指针生成器**将实体从输入的知识数据( knowledge data )复制到输出的文本**
>
> > Suadaa *et al.* [172] **将表值复制到一般占位符中**，以避免产生不出现在输入表中的幻觉短语(hallucinated phrases)。

**Adding Target Information as Input.**  添加目标信息作为输入。

> > 为了解决低保真度的问题， Chen *et al.* [28] 认为，**利用中间意义表示**来实现忠实的生成是很重要的
> >
> > 因此，作者用表示**目标文本语义的逻辑形式**增强了生成模块。

### 3.3 Multimedia Input

除了上述文本数据外，多媒体数据（例如图像、视频和语音）也被用作文本生成算法的输入，例如图像字幕和语音识别。

#### 3.3.1 Image Captioning. 图像字幕。

图像字幕，旨在生成图像的文本描述，已经在计算机视觉（CV）领域得到了广泛的研究。许多研究**提出了多模态的plm来结合文本和视觉模式**

> > 一个著名的**多模态PLM是XGPT** [191]。
> >
> > 受基于文本的GPT的启发，XGPT将图像作为输入，并在训练前阶段使用图像字幕任务作为预训练任务。
>
> > Chen *et al.* [21] 提出了一个图像字幕PLM，称为VisualGPT。
> >
> > 他们设计了一种**自我复活的注意机制(self-resurrecting attention mechanism)**来学习如何编码视觉信息并使其适应PLM解码器
>
> > 然而，**传统的视觉语言预训练未能捕捉到视觉和文本模式之间的关系**
> >
> > Yang *et al.* [200] 提出了**三个预训练的任务**，以有效地学习三种输入数据之间更好的**对齐表示**：文本词、视觉对象和场景文本。

#### 3.3.2 Video Captioning. 视频字幕。

视频字幕侧重于生成可以描述视频内容的自然语言文本。

> **VideoBERT** [174]和**CBT** [173]是研究关于视频字幕任务的视频语言预训练的两个早期尝试。
>
> 然而，**以往的研究通常采用一个单一的编码-解码器框架**，==这对于不同的下游任务并不灵活==。
>
> **UniVL** [129]使用了**两个单模态编码器**来分别对文本和视频进行编码，以及一个**句子解码器**来生成视频字幕。

#### 3.3.3 Speech Recognition. 语音识别。

> 在实践中，语音识别渴望得到人类转录的监督数据。因此，一些**无监督和半监督的方法开发了集成plm用于弱监督学习。**
>
> > Fan *et al.* [45] 提出了一种无监督的方法**对未配对的语音和文本进行预训练**的编码器-解码器模型。
>
> > Liao *et al.* [114]  提出了一种**语音识别后处理模型**，该模型试图利用元数据提取（MDE）语料库构建一个小型的任务特定数据集，将错误的和有噪声的识别输出转换为面向人类和下游任务的自然语言文本

## 4 DESIGNING PLMS FOR TEXT GENERATION 文本生成设计平台

基于PLM的这种结构，文本生成目标可以建模为**给定输入数据𝑥的输出文本𝑦的条件概率**

> 为了计算条件概率，传统的神经模型主要采用具有多个变体[164]RNN体系结构 [177] 
>
> 近年来，仅基于注意机制，Transformer[180]就可以**更好地捕获文本中的长期依赖关系，有利于文本的建模和生成**
>
> > 具有优异的并行化能力
> >
> > 当在大规模未标记语料库[124]上进行训练时，基于Transformer架构的plms可以**编码丰富的语义或语言知识**。
> >
> > 此外，研究表明，**plm可以有效地微调到不同的文本生成任务**[99,168]。

### 4.1 Standard Architecture

 现有的用于文本生成的plm **a single Transformer** or **a Transformer-based encoder decoder** as the backbone

> > plm，如**GPT-3** [14]和**UniLM** [36]，**使用single Transformer编码器 或 解码器来同时实现输入编码和输出解码的过程**。
> >
> > 这包括三个主要的变体：**掩蔽lm、因果lm和前缀lm**（masked LMs, causal LMs, and prefix LMs），**具有不同的注意掩蔽策略**
>
> > 相比之下，建立在**Transformer编码器-解码器上的plm分别执行输入编码和输出解码**。

在下面，我们将详细描述这四种变体。

#### 4.1.1 Masked Language Models. 掩蔽语言模型。

**Masked LMs使用全注意力变压器编码器（ full-attention Transformer encoder）**。在充分注意的情况下，模型通常通过掩码语言建模（ masked language modeling，MLM）任务进行预训练，即使用**双向信息预测掩码标记**

最具代表性的模型是BERT [35]，它在自然语言理解（NLU）中被广泛使用。

然而，==由于**掩蔽lm的预训练任务与下游生成函数之间的差异，掩蔽lm很少被用于文本生成任务** [198].==

> 更常见的做法是==使用掩码的lm作为文本生成的编码器部分，从而允许利用优秀的双向编码能力==。
>
> 例如, Rothe *et al.* [161]提出**用BERT [35]初始化生成模型的编码器和解码器**，这可以产生与其他专门为文本生成设计的plm相当的性能。

#### 4.1.2 Causal Language Models.  因果语言模型。

与Transformer解码器类似，因果LMs采用   **对角掩码矩阵（ diagonal mask matrix）**。

==**因果LMs（Causal LMs）是为语言建模而设计的，它是为了：确定一个给定的单词序列出现在一个句子中的概率。**== 

因果lm对于文本生成很简单，**可以基于之前的所有单词来预测下一个单词。**

> 在文献中，**GPT** [152]是文本生成任务的第一个因果LM。
>
> 然后，**GPT-2** [153]探索了语言模型在 **零射生成任务中(zero-shot generation task)** 的传输能力，**强调了足够数据的重要性**。
>
> 此外，**GPT-3** [14]还表明，通过一些例子或提示(a few examples or prompts)，**大量的模型参数可以显著改进下游生成任务**。
>
> **CTRL** [90]被提出作为一种 **有条件的因果LM**，用于**基于控制样式、内容和任务特定行为的控制代码**。



**因果LMs**对于文本生成非常简单和直接，但它们有几个结构和算法上的限制：

> ==因果LMs**只从左到右编码标记**，因此忽略了输入端的双向信息。==
>
> 此外，==因果lm并**不是专门为序列到序列的生成任务而设计的**==，因此在实践中，它们在摘要和翻译[153]等任务中不能达到高性能。

#### 4.1.3 Prefix Language Models. 前缀语言模型。

在单个Transformer上，前缀LMs在==**输入端采用双向编码方案**==，在==**输出端采用自然的从左到右的生成模式**==

通过 **混合注意掩模(mixture attention mask)**，**输入文本𝑥中的令牌可以==相互关注==**，而**目标文本𝑦中的令牌==只能关注所有的输入令牌和之前生成的令牌。==**

> **UniLM** [36]是第一个前缀LM。与因果LMs相比，UniLM使用 **前缀注意掩码(prefix attention mask) 来解决条件生成任务**，类似于编码器-解码器的结构
>
> **UniLMv2** [5]和**GLM** [39]通过**在XLNet [198]中 引入排列语言建模**，改进了 普通的前缀掩蔽(**vanilla prefix masking**)策略。



虽然前缀LMs有几个优点，但Raffel等[154]将 **单个Transformer前缀LMs** 与 **基于Transformer的编码	解码器LMs** 进行了比较，得出结论：

> ==添加**显式编码解码器注意**可以更有效地捕获 **条件依赖关系。**==

#### 4.1.4 Encoder-Decoder Language Models. 编码器解码器语言模型。

**编码器-解码器lms** 遵循文本生成的标准Transformer架构，由**编码器层和解码器层的堆栈组成**

> 在预训练期间，**MASS** [168]和**PhetNet**[150]以 **一个掩码段的序列作为编码器的输入**，然后**解码器以自回归的方式生成掩码令牌。**
>
> **T5** [154]用 **不同的特殊标记 随机替换源文本中的几个跨度(several spans)，然后解码器依次预测每一个替换的跨度**
>
> 使用**去噪自动编码器（DAE）对BART [99]进行预训练**，即模型学习**从损坏的文本中恢复原始文本**，这些**文本被不同的噪声方法破坏，如句子排列和标记删除。**

### 4.2 Architecture Extensions

为了获得用于文本生成的性能plms，许多研究提出改进PLMs的Transformer主干。在这部分中，==我们将介绍两种主要的改进技术==即：**扩展的输入嵌入**和**改进的注意机制**。

 #### 4.2.1 Extended Input Embeddings. 扩展输入嵌入。

除了（子）单词嵌入外，几乎所有的plm都 **使用==位置嵌入==来表示 输入单词的索引**。与CNN和RNN相比，**自注意操作通常是与顺序无关的。**因此，必须**提供明确的位置信息来捕获文本的顺序性质。**

> **Original Transformer**[180]利用 ==**预先确定的具有正弦函数的绝对位置嵌入**==，而大多数plm（如BERT和GPT）采用 ==**可学习的绝对位置嵌入**==
>
> **相对位置嵌入** 不是绝对位置嵌入，而是==**根据两个标记之间的偏移量产生位置嵌入**==
>
> > **T5** [154]、**UniLMv2** [5]和**PhetNet**[150]采用**桶相对位置法**。
> >
> > 此外，**分层位置嵌入**被用来表示==**句间和句内位置信息**==，这在一些固定格式的文本如诗[109]和词 [195] ( poem and lyric )中经常使用。

此外，还需要**加入辅助嵌入来丰富输入信息**[88]。

> 与BERT中使用的段嵌入类似，**==对话状态嵌入==(dialogue state embeddings)[6,189]用于分配每个话语(utterance)，==用户嵌入==(user embeddings)[6,69]用于区分对话中涉及的字符。**
>
> 在多语言场景中，通常会引入**语言嵌入**[30,168]来告知模型关于每个句子的语言。
>
> 此外，还提出了**押韵嵌入**[109]和**元音嵌入**[195]来表示诗歌和抒情诗中的声学信息

#### 4.2.2 Improved Attention Mechanism. 改进注意机制。

虽然Transformer中存在多种模块（如位置级FFN(position-wise FFN)、自我注意(self-attention)等），相关工作主要集中在改进文本生成[88]的**自我注意机制和交叉注意机制上**。

> 为了适应长文本文本输入，降低全注意计算的二次复杂度，提出了==**稀疏注意( sparse attention)**==来代替长文本输入的原始自注意。
>
> 与其关注所有其他标记，==**每个标记只关注特定的标记**==，如**窗口注意(window attention)[133,143,205]、全局注意(global attention )[143,205]、随机注意(random attention)[205]和信角注意(Sinkhorn attention )[223]**

在实践中，许多文本生成任务需要==处理来自多个源的输入数据==。通常的情况是**利用一个或多个编码器对多个输入进行编码。**

因此，我们提出了一些工作，**利用不同的策略来聚合交叉注意力模块中的多源输入。**

> Golovanov *et al.* [58]对 **对话历史、当前状态和角色信息 平均池化**。
>
> Chen等人[22]和Liu等人[120] 提出的 **多视角注意 和 知识意识注意(multi-view attention and knowledge aware attention)** 来处理来自多个视图或知识源的嵌入。
>
> VECO [128]将一种 **交叉注意技术( a cross-attention technique)** 插入到Transformer**编码器**中，以显式地构建**多种语言之间的相互依赖关系**
>
> BASS [190]和Ribeiro等人[159]用**GNN替换了自注意模块**，以更好地提取结构信息。
>
> Zeng等人，[209]在 **自注意后附加了门控机制(gating mechanism)**，注入**条件感知信息**。

## 5 OPTIMIZING PLMS FOR TEXT GENERATION 优化PLMS为文本生成

为了获得良好的性能，为基于PLM的文本生成模型开发有效的**优化算法**至关重要。

我们考虑了**三种主要类型的优化方法**，即==**微调、提示调整和性能调整**==。我们将在下面详细介绍每种优化方法。

### 5.1 ==$\star$== Fine-Tuning for Text Generation 

在预训练阶段，**PLMs能够从大规模的语料库中获取一般的语言知识**。但是，它==需要特定于任务的知识==来**执行下游的文本生成任务**。

为此目的，==**微调**==是一种流行的方法，通过**使用下游文本生成数据集[153]调整其权重，将任务特定的信息合并到plm中**

根据plm的参数如何更新[88]，现有的==**文本生成微调方法**==可以归类为

> 1)==vanilla fine-tuning==，2)中间微调==(intermediate fine-tuning)==，3)参数高效化微调==(parameter-efficient fine-tuning)==，和4)多任务微调==(multi-task fine-tuning)==
>
> 与vanilla fine-tuning相比，**intermediate fine-tuning和multi-task fine-tuning**可以在一定程度上 *缓解小文本生成数据集上的过拟合问题*。
>
> 由于**vanilla fine-tuning需要调整整个模型**，像adapters[77]这样的**参数高效方法可以以轻量级的方式对plm进行微调**。

#### 5.1.1 Vanilla Fine-Tuning. 直接更新PLMs

Vanilla Fine-Tuning 直接更新plm ==**使用下游文本生成数据集的任务特定的损失**==（例如，交叉熵损失[153]）。

> Zhang等人[215]在GPT-2架构的基础上训练 **DialoGPT**模型，**将 多回合对话会话 建模 为长文本，并利用 语言建模目标 优化生成模型。**
>
> Ribeiro等人[158]研究了两种最近的两个plm，**BART和T5，用于图到文本生成**，并使用**典型的自回归交叉熵损失(the typical auto-regressive cross-entropy loss)**对它们进行微调。

Vanilla Fine-Tuning的一个**主要问题**是，它通常==**在小数据集上没有得到充分的优化，这很容易发生过拟合**==。

#### 5.1.2 Intermediate Fine-Tuning.  中间数据

Intermediate Fine-Tuning的**基本思想**是==**合并一个由 足够的标记实例 组成的 中间数据集(intermediate dataset consisting of sufficient labeled instances)**==



中间数据集可以 专注于**<font color='red'> 来自不同领域的相同目标文本生成任务，或者 来自同一目标域的类似NLP任务 </font>**

> **从中间数据集 注入 特定领域或任务的知识**，可以==**缓解过拟合问题，提高小目标文本生成数据集的性能**==[146].
>
> **根据 中间数据集 与 目标文本生成数据集 之间的相关性**[88]，intermediate fine-tuning可分为 **域自适应中间微调**（domain adaptive intermediate fine-tuning, DAIFT）和 **任务自适应中间微调**（task adaptive intermediate fine-tuning,TAIFT）两类。

**Domain Adaptive Intermediate Fine-Tuning, DAIFT.** 域自适应中间微调 - <font color='red'> 同一目标域的类似的NLP任务 </font>

> 根据Kalyan等人[88]的研究，==**DAIFT利用了一个中间数据集**==，它集中于 来自**==同一目标域的类似的NLP任务==(而不是文本生成任务)，由足够的标记实例组成。**
>
> 通过利用这样的中间数据集，**plms可以丰富地使用特定领域的知识**，这**有助于提高 ==同一领域内== 的目标文本生成任务的性能**。
>
> DAIFT通常用于**机器翻译**，以消除 翻译对 中不可见语言的问题
>
> 例如，为了**提高低资源目标语言（如哈萨克语）的翻译质量**，Liu等[126]构建了一个 **大规模的目标语言中间单语语料库**，并通过 **重构损坏的目标语言文本对mBART进行了微调**。
>
> **中间数据集 与 目标数据集（如哈萨克语）来自==同一语言域==**，可以将 **与语言相关的语言知识 传授给plm，以获得更好的翻译性能。**



**Task Adaptive Intermediate Fine-tuning, TAIFT.**  任务自适应的中间微调 - <font color='red'> 同一任务不同域 </font>

> 与DAIFT相比，TAIFT在==**同一目标文本生成任务上集成了一个来自不同域**==的中间数据集。
>
> 它的目的是从大量的 **中间标记数据集中 注入 特定于任务的知识**，以**改进相同的目标文本生成任务**。
>
> 研究表明，在 **相同的文本生成任务** 上使用 **通用文本语料库**（如维基百科、WebText）进行额外训练**可以提高在特定领域（如电影）上的性能**[42,134]。
>
> 例如，Fabbri等人[42]对 **从维基百科创建的中间伪摘要**( pseudo-summaries)进行了总结，以**提高 zero-shot and few-shot抽象摘要的性能**
>
> 例如，Mao等人[134]对 **中间的库语料库数据集（由WebText构建）进行了生成**，以提高 在目标写作提示数据集(the target WritingPrompts dataset) 上的**常识性故事生成**。

#### 5.1.3 Multi-Task Fine-Tuning. 多任务

多任务微调 ==**可以利用跨任务知识**==，通过结合辅助任务来改进主文本生成任务。

此外，通过从相关的NLP任务中获取知识，**多任务微调可以增强PLMs的鲁棒性，减少了文本生成任务中对大量标记实例的需求。**

根据**主文本生成任务与辅助任务的相似性**，多任务微调（MTFT）可分为 **纯MTFT(pure MTFT)** 和 **混合MTFT( hybrid MTFT)** 两类。

**Pure Multi-Task Fine-Tuning.** 纯多任务微调 - <font color='red'> 辅助任务与主文本生成  任务相同，领域不同， </font>

> 纯MTFT 包含了与==**主文本生成任务相同**但**来自不同领域的**辅助任务。==
>
> 以往的研究主要利用额外的数据集来 消除 主文本生成任务中的 **数据稀缺性问题**[3,61]。
>
> 具体来说，Goodwin等人[61]利用了 **21个额外的总结数据集** 来 **改进对以前未见过的数据集的zero-shot summarization**。
>
> 此外，Bai等人[3]还加入了一个 **辅助的单语总结任务**，以**改进 低资源语言中的主要 跨语言摘要任务**。



**Hybrid Multi-Task Fine-Tuning.** 混合MTFT- <font color='red'> 辅助任务与主文本生成  任务 不同 </font>

> 混合MTFT包含了==**不同于主文本生成任务的辅助任务**==。这些不同的辅助任务可以在不同的方面增强初级生成任务。
>
> 例如，Liu等人[118]和Jin等人[86]**通过辅助任务**（如一致性检测coherence detection、风格携带文本重建style-carrying text reconstruction）**对plm进行微调**，根据主题变化和文本风格（幽默、浪漫和点击诱饵）来控制生成文本的内容。
>
> 此外，为了**提高生成文本的忠实度**，Li等人[105]和Gong等人[60]引入了 **辅助输入重构任务**，重构KG三元组和表值，以便**将输入信息与生成的内容进行对齐。**

#### 5.1.4 Parameter-Efficient Fine-Tuning. 参数高效

由于上述的微调方法需要更新所有的PLM参数，因此**在资源有限的场景中执行整个微调是很耗时的**。许多研究为文本生成任务开发了参数高效的微调（PEFT）

**Adapter-based Parameter-Efficient Fine-Tuning. **基于适配器的参数-高效的微调。

==**适配器(Adapter)**是Houlsby等人[77]提出的一种特殊的神经层，**以参数高效的方式微调plm**==

> 适配器模块 **将输入向量 投影到 一个小向量中**，然后使用 **两个前馈层和一个非线性层投影到 原始维度中**。
>
> 具体来说，适配器首先将原始的𝑑维特征投影到一个更小的维度中，应用非线性，然后投影回𝑑维度。
>
> 每层添加的参数总数，包括biases，是==2𝑚𝑑+𝑑+𝑚==。通过设置𝑚≪𝑑，我们**可以限制每个任务的附加参数的数量。**
>
> 因此，==**固定原始PLM的参数而只对适配器进行微调是非常有效的。**[27,170]。==
>
> 为了 解决**低资源抽象概括( low-resource abstractive summarization)中 的低效率和过拟合问题**，Chen等人[27]**在PLM的编码器和解码器中都插入了适配器，并且只对适配器进行了微调**
>
> <hr>
>
> 一些研究表明，**适配器可以帮助PLM有效地捕捉一些输入特征**，以**生成更准确的输出文本，而参数方面的额外成本很低**[95, 159]。
>
> 例如，Ribeiro等人[159]在对 图输入的PLM进行微调时，**利用适配器对输入的图结构进行有效建模**。

**Freezing-based Parameter-Efficient Fine-Tuning.**  基于冻结的参数-高效的微调。<font color='red'>更新少部分参数，其他冻结 </font>

> 这种方法是指冻结大部分参数，只更新一小部分PLM参数。
>
> 最近的研究表明，在文本生成任务中，**并非所有PLM的参数都需要微调，其中一些参数可以在微调过程中固定下来，而不会对模型性能产生大的影响**。
>
> 一些研究还显示，在为**机器翻译 微调PLM**时，**交叉注意力（或编码器-解码器注意力）层比自我注意力层更重要**[55, 203]。
>
> 因此，Gheini等人[55]**只对交叉注意力层进行了微调，而对编码器和解码器保持固定**。这种方法取得了与微调所有参数相当的翻译性能。



**Distillation-based Parameter-Efficient Fine-Tuning.** 基于蒸馏的参数高效微调  <font color='red'>通过蒸馏进行提炼 </font>

> 另一种参数有效的微调方法是将 large teacher PLMs提炼成 small student models
>
> 通过将PLM中用于 **文本生成的知识提炼成小型生成模型**（如LSTM），学生模型可以有效地进行微调以获得更好的生成性能[26, 167]。
>
> 作为一个代表性的例子，Chen等人[26]**利用BERT作为教师模型，生成单词概率对数的序列**，并**将Seq2Seq模型作为学生网络**，它可以有效地从教师的输出中学习。

### 5.2 ==$\star$== Prompt-Tuning for Text Generation 提示微调

大多数**生成性PLMs都是使用 语言建模目标(language modeling objectives) 进行预训练**，然后**在文本生成任务中以 特定的任务目标 进行微调**。

所以：==**预训练和微调之间的这种差异会影响PLM在文本生成任务上的表现。**== 



作为一种新的学习范式，==提示学习（prompt learning）[119]在预训练中**<font color='red'>把 下游任务（文本生成任务）重塑为语言建模任务</font>**==

#### 5.2.1 Background.

根据Liu等人[119]的说法， prompt function 𝑓𝑝𝑟𝑜𝑚𝑝𝑡（·）通过两步过程将输入文本𝑥转换为prompt 𝑥‘=𝑓𝑝𝑟𝑜𝑚𝑝𝑡（𝑥）：

> 1. 应用一个包含两个槽的文本模板(a textual *template*)：一个输入槽[𝑋]用于输入𝑥，一个中间回答槽[𝑍]用于生成的答案文本𝑧，稍后将被映射到𝑦
> 2. 用输入文本𝑥填充输入插槽[𝑋]。



这里的 提示prompt 可以是**完形填空 或 前缀(cloze or prefix)样式**。

> 在语言理解任务中，通常采用==完形填空提示**(the cloze-style prompt)**==，其中**空槽 [Z] 要么在提示的中间，要么在提示的末尾**
>
> > 例如，在情感分析中，𝑥=“*I love this movie*”，模板可能采取一个封闭的形式，如“[𝑋] It was a really [𝑍] movie” 在[𝑍]中预测答案
>
> 而在 ==前缀样式的提示**(the prefix-style prompt)**==中，**输入文本完全出现在空插槽[𝑍]之前**
>
> > 比如机器翻译中的**“English: [𝑋] German: [Z]”**。前缀提示 在文本生成中被广泛使用，因为它们可以**很好地符合语言建模的从左到右的本质**。

在上面的 提示示例 中，模板由**离散(discrete)**的自然语言标记(tokens)组成，但标记也可以是虚拟词(例如，用数字 ID 表示)，稍后将映射到**连续(continuous) 嵌入**中。

#### 5.2.2 Discrete Prompts 离散提示

早期提示研究通过基于人类内省的**手动设计**模板来创建提示。

> 作为一项开创性研究，GPT-2 [153] 使用各种手动创建的提示 执行文本生成任务。
>
> > 例如，机器翻译中使用提示“translate to french, [input], [output]”。**提示定义了特定文本生成任务中输入数据到输出文本的语义映射**。
>
> 通过利用不同的提示，单个 PLM 能够执行许多不同的文本生成任务。**这些方法严重依赖于手动创建提示**
>
> ==<font color='red'>但是 PLM 对提示高度敏感：创建不当的提示会导致性能低下 [83]</font>。==

为了避免手动指定提示的需要

> Shin 等人 [166] 提出了 **AutoPrompt 来自动搜索模板标记。**
>
> 其他几种自动发现离散提示的方法被提出，例如: **解释现有的提示(paraphrasing existing prompts) [83],使用 PLM 生成提示( generating prompts using PLMs) [51],以及从语料库中挖掘提示(mining prompts from a corpus) [83]**

#### 5.2.3 Continuous Prompts. 连续提示 - soft prompts

**由嵌入向量 组成的 连续提示(Continuous prompts)（又名软提示 soft prompts）被广泛用于文本生成任务**。

==<font color='red'>连续提示 预计有两个主要优点：</font>==

> 1）放宽了 提示模板 应该是 自然语言词汇 的约束；
>
> 2）取消了 模板 由PLM的参数化 的限制。

相反，**连续提示(continuous prompts) 有自己的参数**，可以根据文本生成任务的训练数据进行优化。

使用连续提示进行文本生成的最著名的方法是 **前缀微调(prefix-tuning)**[110]

> 它**冻结了生成性PLM（如GPT-2、BART），并优化了一串特定任务的向量（称为前缀）。**
>
> 与需要 **为每个文本生成任务存储一个经过调整的模型副本的 全参数微调** 相比，**前缀微调 只对每个文本生成任务的前缀进行优化**。
>
> 与前缀微调 类似，一些研究使用连续提示来解决其他文本生成任务，如对话生成[65]。

### 5.3 Property-Tuning for Text Generation 文本生成的属性调整

==对于不同的生成任务，我们在调整PLM时需要**考虑特定的语言属性**==。在本节中，我们将讨论文本生成中广泛需要的**三个主要属性**

#### 5.3.1 Relevance. 相关性

根据语言学文献[107]，在文本生成中，==<font color='red'>相关性(Relevance)</font>== 意味着 **输出文本中传达的主题语义 与 输入文本 高度相关**。

> 作为一个有代表性的例子，在对话系统中，生成的反应应该 与 历史语料和其他条件相关，如说话人的角色和话语主题。



与传统的神经生成模型相比，PLMs利用更强大 ==**多层交叉注意力机制**== 来 **模拟输入和输出之间的语义关联，这可以增强 生成的文本 与 输入数据的相关性**（例如，对话系统[189，215]）。

> 一个很好的例子是基于 **自动回归语言模型**GPT-2的 **DialoGPT** [215]。
>
> > 特别是，DialoGPT首先在大规模的对话对/会话中进行了训练，这可以**使DialoGPT捕捉到对话流中Pr(*ℎ𝑖𝑠𝑡𝑜𝑟𝑦, 𝑟𝑒𝑠𝑝𝑜𝑛𝑠𝑒*) 的联合分布，以便对历史话语产生相关回应。**
>
> 此外，Zeng等人[208]利用 **掩蔽语言建模目标( the masked language modeling objective)** 来解决 **基于不同类型的对话上下文生成的响应**。
>
> > 具体来说，他们提出了一种 **基于TF-IDF的屏蔽( a TF-IDF based masking)，选择更多与条件相关的标记进行屏蔽**，这样PLM就可以生成与条件相关的表达，而不是一般的语言模式。
> >
> > 此外，他们采用了一种 **基于注意力的非参数化门控机制( a non-parametric attention-based gating mechanism )**，在每个位置上生成一个一般的词 或 一个与条件相关的词之间进行切换。

#### 5.3.2 Faithfulness. 忠诚度。

==<font color='red'>忠实性(Faithfulness) </font>== 也是文本生成要考虑的一个重要的语言属性，**这意味着生成的内容 应该坚持 输入文本的语义。**

> 例如，**文本总结**的目的是生成忠实的文本，传达输入文本的突出信息。忠实性有时指的是生成的文本与世界事实相一致。

为了生成忠实的文本，PLMs应该能够准确 **理解 输入的核心语**义，并**获得 足够的 世界知识**来解决下游的任务。

> 已有研究表明，==<font color='red'>PLM在从纯文本中 捕捉核心语义方面 具有出色的自然语言理解能力</font>==[35]，而且它们确实==<font color='red'>编码了大量的世界知识</font>==[83]，这对于**通过向文本注入背景知识来 生成忠实的摘要 有潜在的好处**。
>
> > 例如，Kryscinski等人[93] **在PLMs解码器 中 利用了一个上下文网络** 来**检索源文件中最突出的部分**，以提高生成的摘要的忠实程度。
>
> 此外，一些研究提出通过 **引入除文本生成损失之外的额外损失** 来生成忠实的文本[161, 202]。
>
> > 具体来说，Yang等人[202]通过 **主题建模损失** 对PLM进行了微调，其目的是使生成的摘要在语义上接近原始文章，以实现忠实的生成。

#### 5.3.3 Order-Preservation. 顺序保留。

在NLP领域，<font color='red'>顺序保留(Order-Preservation) </font> 是一个特殊的属性，指的是 **输入和输出文本中的语义单位（词、短语等）的顺序是一致的**。

这样的属性是 几个重要文本生成任务的关键，如文本解析和机器翻译。

在**==机器翻译中==，当从源语言翻译到目标语言时，往往需要保留 源文本和目标文本中 一些短语的顺序，以确保翻译结果的准确性**。

在机器翻译中，==**单词对齐**==是一个广泛研究的方法，以实现 顺序保留 的特性。

> 一个代表性的研究是 **编码转换预训练（Code-Switching Pre-training, CSP）**[199]。CSP首先 从源语和目标单语语料库中 自动提取 **词对对齐信息**。
>
> 然后，为了增强 翻译过程 中的保序性，CSP 通过在目标语言中 给定对齐片段的情况下 预测 源端的句子片段 来持续预训练 PLM。

此外，为了**放宽 离散词对齐 的限制**，另一项研究旨在进行 ==**连续的表示对齐**== 以提高保序性。

> Wada 等人 [182] 专注于 通过 **将每种语言的词嵌入 映射 到 一个共同的潜在空间** 来**对齐每种语言的词表示**。
>
> Lin 等人 [116] 提出 mRASP 来强制 **将多种语言中具有相似含义的单词和短语 在表示空间中对齐**。

## 6 CHALLENGES AND SOLUTIONS 挑战和解决方案

前面三节描述了三个关键方面，以及基于PLM的文本生成的基本方法。在本节中，我们进一步讨论每个方面的主要挑战和可能的解决方案。这些挑战和解决方案的摘要见表1。

<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/202301311341294.png" alt="image-20230131134109533" style="zoom: 67%;" />

### 6.1 Data Aspect 数据

#### 6.1.1 ==$\star$== Lacking Sufficient Training Data. 缺少足够的训练数据。

在一些文本生成任务中，很难获得足够的注释数据。**迁移学习(Transfer learning )** 通过 将数据丰富的源任务的知识 转移到 数据稀缺的目标文本生成任务中，提供了一个有效的解决方案。此外，**数据增强(data augmentation)和多任务学习(multi-task learning)**也可以用来解决这个问题。

**Transfer Learning.** 迁移学习

为了处理数据稀缺问题，一些研究提出 ==**首先在大量的外部标记语料上对PLM进行微调，然后转入数据稀缺的目标文本生成任务**==[120, 144, 227]。

> 特别是，Peng等人[144]和Zou等人[227]首先在 大量标记的对话/摘要数据上对PLM进行了微调，然后在一个标记数据有限的新领域中为目标对话/摘要任务进行了微调。
> 同样，Liu等人[120]首先在 **大规模 无基础对话和非结构化知识库 上分别训练模型**，以改进低资源知识基础的对话生成任务。

**Data Augmentation.**  数据增强

在最近的文献中，数据增强已经成为一种重要的方法，通过==**增加已经存在的数据的轻微修改的副本 或 从现有数据中新创建的合成数据 来增加数据量**==。

> 一个研究方向是使用 检索模型(retrieval models) 从外部语料库中获取真实数据作为增强数据[142, 193]。
>
> > 对于以 **查询为中心的总结任务**，Pasunuru等人[142]使用**搜索引擎，即Bing**，检索出 答案段落作为合成总结，并使用排名靠前的文档作为输入文本。
>
> 另一条工作路线是通过 **破坏原始文本** 来使用==**基于扰动的方法**==[23, 131]。
>
> > 例如，Chen等人[23]提出了一套用于 对话总结的数据增强方法，如随机交换/删除，**在对话中随机交换或删除语料**。

**Multi-Task Learning.**  多任务学习

利用 ==**其他数据丰富的任务和数据集**== 也可以克服数据稀缺性的问题。大多数研究通常 **采用类似的辅助生成任务来增强初级文本生成任务**[61]。

> 然而，这些方法通常 **为每个任务采用独立的解码器(decoders)**，从而**打破了高资源和低资源文本生成任务之间的语义联系**。
>
> 为了弥补这一差距，Bai等人[3]采用了一个 **统一的解码器，在机器翻译中学习多种语言的排列组合和模式**。

#### 6.1.2 Data Bias from Pre-training Corpora. 来自预训练体的数据偏差

在社会学中，偏见是指对一个人、一个团体或一件事的赞成或反对的无理偏见[54]。

**PLMs**一般使用真实世界的数据进行训练，其方式是**对训练数据的统计属性进行建模。**

因此，他们继承了数据中常见的偏见和刻板印象(biases and stereotypes)[54]。这些**偏见和刻板印象会给下游的文本生成任务带来重大挑战**[14]。

<hr>

已有研究表明，**从PLMs中生成的文本很可能偏向某些属性**[14]，即偏向某个种族、性别或老年人，这对于文本生成任务来说是不可取的。

> 这些不受欢迎的**偏见意外地隐藏在模型组件中，如词嵌入[10]和注意头[181]**。缓解词嵌入中的性别偏见的**一个简单方法是在生成词嵌入时将训练数据中的性别词进行 "交换"**[221]。
>
> 此外，简单地 **掩盖名字和代词( masking names and pronouns )**也可以减少偏差，提高某些语言任务的性能[34]。然而，到目前为止，仍然没有一个普遍的、统一的方法来减少PLM对文本生成的数据偏差。
>
> 其中一些检测和缓解偏见的技术被批评为 仅仅是捕捉了偏见的过于简单的维度，而适当的 去偏 需要更全面的评估[59]。

### 6.2 ==$\star$== Model Aspect - 压缩PLMs

在这一节中，我们介绍了架构设计中的挑战，并讨论了文本生成的相应解决方案。

#### 6.2.1 Model Compression.模型压缩

尽管PLMs在文本生成方面取得了巨大的成功，但**骨干Transformers仍然很笨重，对资源要求很高，导致高内存消耗、计算开销和能源成本**。

为了解决这些问题，人们提出了越来越多的方法来 压缩PLMs[50]，如 **量化、剪枝和知识蒸馏==(quantization, pruning, and knowledge distillation)==**。

**Quantization.**  量化

量化(Quantization) 意味着：==**减少用于表示PLMs权重的唯一值的数量**==，这反过来允许使用更少的bits来表示它们[50]
<hr>

由于大多数PLMs是建立在Transformer基础上的，**量化**一般可以应用于那些 **在全连接的层（即嵌入层、线性层和前馈网络层）的权重**。

但是，**当模型参数被压缩时，生成能力（ generation capacity）可能会降低**。

* 为了缓解使用截断的PLMs产生不满意文本的问题，==<font color='red'>一个很有前途的解决方案是：**首先识别重要的权值，然后在量化步骤中避免截断它们**[204]</font>==

**Pruning.** 剪枝

剪枝(Pruning) 是指：识别和删除多余的和/或不太重要的权重[50]。文本生成的修剪方法主要分为两类[50]。

> 第一种 ==**非结构化修剪(unstructured pruning)**== 是通过**定位PLMs中 最不重要的权重集 来修剪单个权重。权重的重要性可以通过特定的指标来衡量，如绝对值[62]和梯度[68]。**
>
> 第二种 ==**结构化修剪( structured pruning)**== 是 **通过减少和简化某些模块**，如注意头[76]和变形器层[44]，**来修剪结构化的权重块(structured blocks of weights )，甚至是PLMs的完整组件(complete components of PLMs)。**

**Knowledge Distillation.** 知识蒸馏

知识蒸馏(Knowledge Distillation) 是指 **使用PLMs（称为教师）的输出 来训练 一个较小的模型（称为学生）**。

> 首先，学生模型可以 **直接从PLMs中最后的softmax层的输出单词分布中学习**，这使得==学生可以通过复制**整个词汇的单词分布**来模仿教师的生成文本==[26]。
>
> 其次，学生也可以 **从PLMs编码器的输出张量中学习**[103]。==直观地说，**PLMs编码器的表示可能包含 有意义的语义 和 输入标记之间 的上下文关系**，这有助于生成准确的文本。==
>
> 第三，通过 **复制输入数据和输出文本之间的注意力分布**，学生也可以==学习**输入 和 输出之间的上下文依赖关系**==[85] 。

#### 6.2.2 Model Enhancement. 模型增强

尽管如今PLMs已经取得了巨大的成功，但离我们的期望还有很大的差距。最近，研究界对 **加强现有的PLMs 以提高文本生成的性能** 的兴趣大增。

**Large-scale PLMs.** 大规模的PLMs - ==扩大参数==

Kaplan等人[89]表明，**通过扩大PLM的参数量，可以提升PLM的性能**。

> 这一观察引发了文本生成中大规模PLMs的发展[14, 207]。用于文本生成的最具代表性的 大规模PLMs是**GPT-3**[14]，它包含1750亿个参数，比以前的任何非稀疏PLMs多10倍。
>
> 在有大量参数的情况下，GPT-3可以在各种文本生成任务中取得强大的性能，而**不需要进行任何梯度更新或微调。**



**Knowledge-Enriched PLMs.** 知识丰富的plm - ==整合外部知识==

最近的研究发现，**整合来自外部知识来源的知识**可以提高PLMs的文本生成性能 [175,225]。

> 具体来说，ERNIE 3.0[175]在一个 **由普通文本和大规模知识图谱组成的4TB语料库** 上进行了预训练，用于语言理解和生成任务。
>
> 在不包含显式知识的情况下，CALM [225] 可以 **通过预训练策略 教 PLMs 使用 常见概念编写和推理，从而 将常识知识编码为参数**，从而在文本生成任务上产生更好的性能。



**Efficient PLMs.** 高效的PLMs - ==精心构造模型架构==

在大规模文本数据上预训练 PLM 的成本高得令人望而却步。

最近，已经证明，**通过精心构建模型架构，可以用更少的预训练数据 [225] 或 更低的预训练成本 [84] 获得同等或更高的文本生成性能**。

> 例如，CALM [225] 开发了一个 **具有生成和对比目标的相互增强的预训练框架**，从而实现了与其他较大的 PLMs（例如 T5）相当的结果，同时仅在小型语料库上进行了几个步骤的预训练。

### 6.3 Optimization Aspect 优化方面

在这部分中，我们将讨论关于针对文本生成的优化plms的挑战和解决方案

#### 6.3.1 Satisfying Special Text Properties. 满足特殊文本属性

在 5.3 节中，我们介绍了**三个基本的文本属性(相关，忠诚，顺序保留)**。在本节中，我们将介绍文本生成任务的**三个更难的属性，即连贯性、真实性和可控性（coherence, factuality, and controllability）**

**Coherence.**  连贯性

在语言学 [101] 中，**语言连贯性（language coherence）**是==使多句文本在逻辑上和句法上都有意义==的原因。

==**提高连贯性的一个基本技巧**是 精心规划生成的内容，这被称为 **文本规划（text planning ）**== [78、107]。

> 例如，Li等[107]设计了一个 **基于两层文本规划(text plan)的文本生成模型**：(1) **文档规划 按顺序建模为一系列 句子计划**，以及 (2) **句子计划 建模为来自 KG 的基于实体 的子图**。
>
> > 局部连贯性 由 KG 子图自然地强制执行，并且可以通过 **生成连贯的子图序列(a coherent sequence of subgraphs)** 来提高 全局连贯性
>
> Wang等[186]提出了一个 两阶段的规划(a two-stage planning)，即第一阶段是组织故事大纲，说明故事情节和事件，第二阶段是 将大纲扩展成一个完整的故事。



**Factuality.** 实际情况

文本生成任务（例如，表格到文本生成）的输入数据（例如，信息框）通常包含一些事实信息。在这种情况下，==**生成的内容应符合原始输入事实**==。

然而，**缺乏对输入事实的 直接获取 或 明确的监督 使得 PLM 无法在生成过程中保留文本的真实性**。

> 对于数据到文本的生成，通常采用**指针生成器(pointer generator) [**164] **将输入事实 复制到 输出**中以保持真实性 [29、105]。
>
> 此外，为了使摘要模型产生更多的事实摘要，一些研究**提出了 评估指标 或 校正方法** 来衡量和修改生成的文本 以保持真实性 [37, 135]



**Controllability.**  可控性

在文本生成中，**许多应用程序需要很好地控制输出文本**。例如，为儿童生成阅读材料，我们希望引导输出的故事安全、具有教育意义且易于儿童理解。

> The Plug and Play Language Model，也称为 PPLM [33]，是可控 PLM 的一个示例，它**将 PLM 与一个或多个简单的 属性分类器 相结合，无需进一步的 PLM 训练即可直接生成文本。**
>
> 一些研究 **从分布的角度(a distributional view)实现了可控性** [91, 141]。
>
> > Pascual 等人 [141] 描述了一种在单个句子中 即插即用的解码方法(a plug-and-play decoding approach)：**给定一个主题或关键字，该模型将词汇表上的概率分布 转移到 语义相似的词**		

#### 6.3.2 ==$\star$== Mitigating Tuning Instabilities. 减轻微调的不稳定性

由于 PLMs 的**灾难性遗忘性质 和 文本生成数据集的小规模**，为文本生成 **调整 PLM 通常是不稳定的**，即使用不同的随机种子微调模型会导致性能差异很大。

可能的解决方案包括 **中间微调、mixout  和 使用监督对比损失(intermediate fine-tuning, mixout and using supervised contrastive loss)。**



**Intermediate Fine-Tuning.** 中间微调 - ==用丰富中间标记数据训练==

最近的研究表明，首先 **在数据丰富的 中间标记数据集(intermediate labeled datasets)**（例如，来自同一目标域的类似 NLP 任务）**上训练 PLM**，然后 **再在数据稀缺的目标文本生成任务上对其进行微调**，可以在目标任务中取得更好的性能 [126, 146] .

> 例如，Liu 等人 [126] 构建了目标语言（例如哈萨克语）的**中间单语语料库**，并**微调 mBART 以重建损坏的单语文本**，以提高低资源目标语言的翻译质量。



**Mixout Strategy.** 混合策略 - dropout 的变体: mixout

在微调 PLMs 时，**dropout [169] 已被用作正则化方法，以防止只有少量训练实例时性能下降。**

> Lee 等人 [97] 引入了 **dropout 的变体: mixout**，它==随机混合两个 PLMs 的参数。==
>
> **The mixout strategy** 可以通过 最小化 与两个PLMs之一的偏差来 规范学习，并且规范化的强度 沿着优化轨迹进行调整。



**Contrastive Learning.**  对比学习

文本生成中**最常用的 交叉熵损失，即 标签的独热向量 与 模型输出分布 之间的 KL 散度**，==对噪声标签 [219] 或对抗性样本[41] 缺乏鲁棒性。==

因此，具有 交叉熵损失的微调 PLM 往往不稳定，尤其是在标记数据有限的情况下。

> 一个有效的解决方案是：==**捕捉一个类中示例之间的相似性，并将它们与其他类中的示例进行对比**== [67]。
>
> 为此，Gunel 等人 [67] **将 交叉熵损失 与 监督对比学习损失相结合**(combined the **cross-entropy loss** with **a supervised contrastive learning loss**)，将来自同一类的词推近，将来自不同类的词推得更远。



## 7 EVALUATION AND RESOURCES 评估和资源

在本节中，我们将讨论关于用于文本生成的plm的 几种常用的 评估度量 和 资源

### 7.1 ==$\star$== Evaluation 评估

随着文本生成应用程序和数据集的不断增长，**自动评估有几个优点**：它可能比人工评估便宜得多、更快，而且它是可复现的[8]。

因此，本部分主要关注文本生成的自动评价指标。继Celikyilmaz等人[19]之后，我**们提出了四类指标**，==<font color='red'>即𝑛-gram重叠指标、多样性指标、语义相似度指标 和 基于logit的指标</font>==(*𝑛*-gram overlap metrics, diversity metrics, semantic similarity metrics, and logit-based metrics)。

我们在表2中列出了在每个文本生成任务中使用的指标。

<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/202302011128979.png" alt="image-20230201021027567" style="zoom:70%;" />

#### 7.1.1 N-Gram Overlap Metrics.𝑛-gram重叠指标 - 词

这些指标 衡量机器生成的文本和真实文本 **<font color='red'>在单词级别上的 词“匹配”程度</font>**。

**BLEU.** 

双语评估替补 (The Bilingual Evaluation Understudy, **BLEU**) [140] 是用于比较 ==**两个句子相似性的**== 首批指标之一。

> 该指标最初是 **将文本的候选翻译 与 一个或多个参考翻译进行比较**，原为机器翻译提出的，现在应用于各种生成任务
>
> **BLEU-𝑛测量** ==生成的文本和真实文本之间*𝑛*-grams 共现的精度，并 对较短的生成文本进行长度惩罚。==
>
> 特别地，建议将 SacreBLEU [149] 用于机器翻译以避免不一致问题。
>
> 还提出了几种平滑方法[20]来 评估短句

**ROUGE.** 

Recall-Oriented Understudy for Gisting Evaluation,   **ROUGE** [115] 是一组度量，**用于测量 由多个句子组成的长文本的自动摘要**	

> ROUGE-n 计算生成文本和真实文本之间**重叠的 n-gram 的 F1 分数**。

**METEOR.**

提出了具有显式排序的翻译评估指标 ( The Metric for Evaluation of Translation with Explicit ORdering，**METEOR**) [4] 来解决 BLEU 中发现的一些问题。

> 与 BLEU 相比，METEOR 是**基于unigram精度和召回率 的调和平均值计算的，并基于WordNet测量生成文本与真实文本之间的 词对词匹配**。

**ChrF++.**

字符𝑛-gram的F-score（ChrF++）[148]是 机器翻译的自动评估指标

> 与BLEU的词级共现不同，**ChrF++主要集中于字符级匹配，从而考虑语素重叠**。

#### 7.1.2 Diversity Metrics.多样性指标 - 词汇多样性

许多文本生成任务都**需要词汇多样性**，例如 对话系统和故事生成。对于这些任务，有必要对生成的文本进行多样性评估。

**Distinct.** 

Distinct-𝑛 通过计算生成文本中 **不同*𝑛*-grams的数量** 来衡量多样性的程度 [100]。

这个度量 **根据生成的tokens总数进行缩放，以避免偏爱长句子**。

#### 7.1.3 Semantic Similarity Metrics.语义相似性度量 - 语义

上述指标侧重于字面词比较。许多研究还提出 比**较生成文本和真实文本之间的 隐式语义**。

一种典型的方法是 ==将生成的文本和真实文本 映射到句子向量中==，然后比较它们的**嵌入相似性**。

**BERTScore.**

> 鉴于BERT在许多任务中的出色性能，BERTScore [213]**利用了来自BERT的预训练的上下文嵌入，并通过余弦相似度来比较候选文本和参考文本中的单词**。
>
> BERTScore已被证明与人类 **在句子级和系统级评估**上的判断很一致[19]。

#### 7.1.4 Logit-Based Metrics.基于 Logit 的指标 - 概率视图评估

$P r ( y ) = \prod _ { j = 1 } ^ { n } P r ( y _ { j } | y _ { 1 : j - 1 } ; x )$, 	and *𝑦*1:𝑗−1 denotes the previous tokens ⟨*𝑦*1, . . . , 𝑦𝑗−1⟩.

基于logit的指标 **从 概率视图 中评估生成的文本**。

**PPL.** 困惑度

在信息论中，**困惑度** (perplexity，PPL) 是 **衡量 概率分布或概率模型 预测样本 与 真实情况相比的好坏程度** [12]。

> **低困惑度**表示 概率分布 **善于预测样本**。因此，离散概率分布Pr(·) 的困惑度定义为：[ H(Pr(𝑦)) 是Pr(·) 分布的熵。]
>
> <img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230201204659013.png" alt="image-20230201204659013" style="zoom: 67%;" />

### 7.2 Resources

在本节中，我们将介绍一些可用的开源库和基准测试。

#### 7.2.1 Open-Source Libraries.  开源库

有许多公共文本生成库可用于实施基于 PLM 的文本生成模型。

> **Transformers** [188] 是一个用于基于 Transformer 的 PLMs 的全功能库
>
> **Fairseq** [137] 是一个用于为 翻译、摘要、语言建模和其他文本生成任务 **训练自定义模型** 的库。
>
> 此外，一些库，如**FastSeq** [196]、**DeepSpeed**[156]和**LightSeq** [187]，都有助于提高模型的推理速度。
>
> **TextBox** [104]支持21种文本生成模型，包括 几种流行的PLMs，以及**不同的生成策略（例如，top-𝑘，波束搜索 beam search）**和 **评估度量（例如，BLEU，Distinct）**

通过只需几行代码就可以设置相应的超参数，就可以很容易地选择不同的plms、优化方法 和 评估度量。

#### 7.2.2 Evaluation Benchmarks 评估基准。

为了评价plms的综合能力，我们创建并发布了几个重要的评价基准，其中涉及到来自不同方面的多个评价任务。

除了**GLUE** [184]和**SuperGLUE** [183]这是**一般语言理解的评估**基准外，最近还提出了越来越多的 针对文本生成 的一般基准。

Liu等人[117]介绍了 **通用语言生成评估（General Language Generation Evaluation，GLGE）**基准，这是一种新的多任务基准，用于==**评估文本生成的泛化能力**==

> GLGE包含 8个英语语言生成任务，包括：摘要、问题生成、生成式问题回答和对话。
>
> 对于每个任务，GLGE根据任务难度设计三个子任务（即GLGE-Easy、GLGEMedium和GLGE-Hard）

## 8 ==$\star$== APPLICATION 应用

如在 第2章(介绍了任务的定义和PLMs的概述) 中所讨论的，文本生成可以被实例化到不同类型的应用程序中。

为了总结现有的文本生成应用程序，我们在表2（7.1节表2）中提供了不同任务（以及相应的公共数据集和度量标准）的概述。

在接下来，我们将**强调三个经典的应用，即 机器翻译、文本摘要 和 对话系统**，并简要讨论如何设计特定任务的PLMs来适应特定的文本生成任务。

### 8.1 Machine Translation

机器翻译 (MT) 是将一种语言自动翻译成另一种语言的过程。

随着深度学习的出现，神经机器翻译 (NMT) 已成为 学术研究和商业使用 中的主导方法 [32]。

**机器翻译可以分为两种类型**：==无监督机器翻译 和有 监督机器翻译==，这**取决于是否有 并行语料库 可用于微调 PLM。**

#### 8.1.1 Unsupervised Machine Translation. 无监督的机器翻译 - 单语语料库上进行预训练

无监督机器翻译（UMT）指的是 **仅使用单语语料库，没有任何并行数据，用于预训练和微调PLMs**。

UMT使机器翻译**不再依赖于 大规模的注释语料库(large-scale annotated corpora)**，也在低资源的语言翻译方面带来了显著的进步



当为UMT（无监督）使用PLMs时，通常有涉及两个步骤[94]：

> 1. PLMs在 **多种语言的 单语语料库上 进行预训练**，==学习单词嵌入 和 每种语言中的每个句子的建模概率==
> 2. 然后==**迭代反译(Iterative back-translation)**==，将 **源到目标和目标到源的模型（the source-to-target and
>    target-to-source mode）** 与 **去噪的自动编码和反向翻译目标（denoising auto-encoding and back-translation objectives.）** 结合起来。

<hr>

**Pre-training on Monolingual Corpora.** 单语语料库的预训练。

最近基于PLM的**研究主要集中在UMT的第一步**。

> 具体来说，**XLM** [31] 和 **mBERT** [35] 使用 MLM 任务对 **多个单语言数据 进行预训练**，然后**使用 PLM 初始化** 机器翻译的编码器和解码器。
>
> **mBART** [122]遵循了BART [99]在多种语言上的预训练方案，而这些PLMs只是使用 **混合单语语料库( mixed monolingual corpora)** 执行原始的预训练任务，而没有考虑语言之间的关系。
>
> **CMLM** [157]进一步**提出了 跨语言MLM(cross-lingual MLM) 来随机屏蔽单语句子中的标记**，并预测相应的 翻译候选对象；因此，CMLM**能够对齐不同语言的嵌入。**
>
> **CSP** [199]也有类似的想法，用 源句中的一些单词替换成 翻译的单词，然后**预测被替换的单词**



**Leveraging Iterative Back-translation.** 利用迭代反译

在反向翻译阶段，Garcia 等人 [53] 提出 **使用多任务学习**。

> 他们调查了多语言 UNMT，这涉及 **将一种语言翻译成另一种语言时 使用第三种语言**，额外的语言 可以提供 **辅助的单语数据 或 仅包含源语言或目标语言中的一种语言的并行数据。**
>
> 他们汇总了 **反向翻译损失(back-translation loss)** 并引入了 一个**交叉翻译术语(a cross-translation term)** 来合并辅助语料库。

Li 等人 [113] 也应用了**交叉翻译术语(a cross-translation term)** ，另外还包括第三（中间）语言的 **知识蒸馏目标**。

#### 8.1.2 Supervised Machine Translation. 有监督机器翻译 - 平行语料库上微调

有监督机器翻译 (SMT)  是指 **基于平行语料库(parallel corpora)的微调 PLMs**。在这里，我们将讨论如何利用现有的自监督 PLMs，以及如何为平行语料库设计 PLMs。

<hr>

**Directly Fine-tuning Unsupervised PLMs.**    有监督：**==对无监督 PLMs微调== - 无监督(自监督)预训练PLM都可用 双语对 微调**

几乎**所有上述使用 无监督（自监督）预训练的 PLMs**，例如 XLM [31] 和 mBART [122]，**都可以直接 用双语对(bilingual pairs) 进行微调。**

> 此外，考虑到BERT优秀的编码能力，**BERT-fused model**[226]利用 **BERT提取 源句的上下文嵌入，并将 表示 与 编码器和解码器 的每一层进行融合**。
>
> **CTNMT** [197]利用 **渐近蒸馏( asymptotic distillation) 和 动态切换门(dynamic switching gate)** 来融入BERT嵌入。
>
> **Graformer**[176]嫁接 **mBERT作为编码器，mGPT作为解码器**，然后训练一个 **交叉注意模块(a cross-attention module)** 将其组合起来。
>
> Tang等人[178]提出 对 多种语言对 上的mBART进行微调，称为**多语言微调**。



**Designing PLMs for Parallel Corpora.** 为并行语料库设计PLMs - ==利用不同语言 相同含义单词==

大多数 PLMs 使用 **自监督的预训练任务**（例如 MLM 和 DAE）**在 单语 语料库上进行预训练**。然而，这些**预训练目标与下游翻译任务不同**。

> 因此，**mRASP** [116] 通过用在 其他语言中具有相同含义的单词 **随机替换** 源句子中的单词，对具有监督 Seq2Seq 损失的 双语对模型进行预训练。

因此，鼓励在不同语言中==**具有 相似含义的词 共享相似的表示**==。

> **mRASP2** [139] 应用 **对比学习** 来 **最小化相似句子的表示差距** 并 **最大化不相关句子的表示差距**。

尽管取得了巨大成功，但并行数据的预训练需要大量的人力和财力来创建大量的双语对

### 8.2 Text Summarization - 抽象摘要

文本摘要是将文本压缩成简短摘要的过程，该摘要保留了源文本中的关键信息 [40]。

==**基于 PLMs 的文本摘要的主流方法**==是 **提取式 或 抽象式**。

> **提取摘要**(Extractive summarization) 从 **源文本中选择句子的一个子集** 并 将它们**连接**起来形成摘要 [123, 214]。
>
> 相反，**抽象摘要**(abstractive summarization) 从 输入文本的抽象表示中自动生成摘要 [164、211]。
>
> ==由于抽象摘要与文本生成更相关，所以我们在本节中只讨论 **抽象摘要**。==

#### 8.2.1 Document Summarization.文档摘要

文档是一种广泛使用的文学形式，例如新闻、观点、评论和科学论文。

PLMs，例如 UniLM [5, 36]、MASS [168]、T5 [154]、BART [99] 和 PEGASUS [211]，**可以直接针对文档摘要进行微调**。

==<font color='red'>**在预训练期间**，这些模型学习了 **根据剩余的句子 来预测 输入文档中被屏蔽的重要句子**，这与摘要的思想相似。</font>==

<hr>

在没有直接生成摘要的情况下，一些研究**首先 提取关键字、关键句子 或 关系 作为指导(guidance)，然后将它们与 PLM 结合起来生成。**

> CIT[162]采用RoBERTa[124]从输入文件中提取重要的词和句子。
>
> 此外，话题模型(topic models) 被用来捕捉文档的 **全局话题语义(global topic semantics)**，这可以被整合到总结模型中[136]。
>
> GSum[38]提出了一个通用框架，**将不同种类的 指导信号(guidance signals) 纳入生成模型**，包括关键词、三要素、突出的句子和检索到的摘要。

除了 外部指导( external guidance) 外，还有一些 技巧 可以应用于文档总结。

> Cao等人[16]**改进了 注意力机制** 以强调文件中的突出内容。
>
> Refactor[121]首先在不同的设置下 生**成多个摘要，然后对其进行评分**，最后选择一个最佳候选摘要。

#### 8.2.2 Dialogue Summarization. 对话摘要

对话，如聊天和医疗对话，由两个或更多人的多轮话语组成。因此，捕捉 半结构化的对话内容 和 用户在对话中的互动 是至关重要的[47]。

对于对话总结来说，==**直接重复使用 文档摘要（Document Summarization） 模型**== 是很简单的。

> Zhang等人[212]首先 **将对话文本截成若干chunks，然后将每个chunk总结为部分摘要**，最后将 这些部分摘要 改写为完整的摘要。

同时，一些研究也探讨了对话的一些 **具体特征**，以改善对话总结。

> Chen等人[22]首先从对话中 提取 **不同的主题视图**，然后利用 **多视图解码器( a multi-view decoder)** 将这些视图组合起来生成摘要。
>
> 此外，Chen等人[24]构建了 **对话的话语关系图和行动图**，以便集中于最突出的话语，了解用户行动的具体细节。

考虑到对话的低信息密度(low information density)、话题漂移(topic drifts)和频繁的核心内容(frequent coreferences)[47]，一些研究者进行了 **辅助任务** 来提取对话的内在信息。

> Feng等人[48]利用DialoGPT[215]，一个专门为对话设计的PLM，来自动 **提取关键词，检测多余的话语，并将对话 划分为主题一致的片段**。

### 8.3 Dialogue System 对话系统

对话系统（又称，**对话代理， conversational agent**）旨在使机器与人流畅地交流。从技术上讲，机器需要产生 **以历史背景为条件** 的反应。

根据下游应用，==对话系统通常**被分为 开放领域(open-domain)和面向任务(task-oriented) 的对话系统**。==

> 前者旨在与人类就日常生活、体育和娱乐等**开放性话题**进行对话[80]；而后者则专注于**协助用户完成特定任务**，如酒店预订和产品购买[220]。

#### 8.3.1 Open-domain dialogue System. 开放域对话系统

开放域对话系统也被称为专注于日常聊天的聊天机器人。例如，微软的XiaoIce是一个著名的开放域对话系统，以满足人类对交流、亲情和社会归属的需求[224]。

**Continuous Pretraining with dialogue Corpora.** 使用对话语料库 连续预训练 - ==**采用非正式文本资源**==

PLMs，如GPT-2，是在一般的**文本语料库上预训练的**，因此各种研究 **不断地预训练通用PLMs 以适应对话系统**。

由于难以获得大规模的对话语料，通常采用 **非正式的文本资源**（如Reddit、Twitter和微博的论坛帖子和评论）进行持续的预训练。

> 作为两个典型的模型，DialoGPT[215]和Meena[1]使用 **英文或中文对话语料库** 来不断地预训练像GPT-2这样的casual LMs。
>
> 此外，Blender[160]和PLATO[6] **利用Seq2Seq损失，根据以前的话语生成下一个话语**。
>
> 此外，PLATO[6]加入了 **下一句话分类（ next utterance classification, NUC）损失**，类似于BERT中的下一句话预测任务，以判断回应 是否与历史对话有关，从而**增强语篇的连贯性**。
>
> **为了惩罚平淡无奇的反应(bland responses)和减少重复(decrease repetitions)**，DialoGPT[215]采用了 **相互信息最大化(mutual information maximization)** 来预测给定的输入 生成的回应(response)
>
> Blender[160]采用了 **不可能的训练目标(unlikelihood training objective)** 来惩罚重复的*n*-grams。



**Directly Fine-tuning Existing PLMs.** 直接对现有的PLMs进行微调

除了在对话语料库上进行预训练外，研究人员还探索了在对话任务上 **对现有的PLMs进行微调**。

> TransferTransfo[189]通过 **多任务学习** 使GPT适应于对话任务。
>
> 在TransferTransfo的基础上，Golovanov等人[58]修改了架构，以更好地**模拟多种输入，包括对话历史、角色信息和当前状态**。
>
> 此外，为了 捕捉对话的层次结构，人们提出了 **层次化的编码器(hierarchical encoders)** 来模拟对话输入[64, 112]。
>
> Gu等人[64]提出了一个**分层框架**，即dialogueBERT，它使用 **句子和话语级别 的Transformer编码器**，分别**对每个对话话语和话语向量序列进行编码。**

此外，在对话系统中，**可控性(controllability)** 也是需要考虑的重要因素。

> Zeng等人[209]利用 **条件感知的Transformer块(condition-aware Transformer block)** 来引导 特定主题标签中的 响应。
>
> StyleDGPT[201]试图在 单词和句子级别 上使用 **KL损失** 来强制执行 生成的响应的目标风格。

#### 8.3.2 Task-Oriented Dialogue System.

面向任务（又名，**面向目标，goal-oriented**）的对话系统是现实生活中广泛使用的 文本生成应用，例如帮助用户订票。

通常，**面向任务的对话系统分为四个模块，即自然语言理解、对话状态跟踪、对话策略学习 和 自然语言生成**[220]。

**大多数以前的工作只关注**使用生成 PLMs（例如 GPT）的 面向任务的对话系统中的 ==**最后生成模块**==。

> 例如，SC-GPT [144] 使用 **前三个模块的 真实结果**（例如，对话状态）并 将它们**序列化为 最后生成模块 的输入 以生成响应**。
>
> Kale 等人 [87] 进一步设计了一个 **手动模式(a manual schema)**，以更好地将以前的结果 转换 为自然语言。
>
> Shalyminov 等人 [165] 建议 **根据对话上下文 生成和检索多个响应**，并利用 NUC(next utterance classification) 任务选择最佳响应。
>
> PRAL [63] **利用两个独立的 GPT-2  对用户和系统 进行建模**，并采用**第三个 GPT-2 进行知识蒸馏**，并将常识知识纳入最终的对话生成中。

此外，越来越多的研究提出 ==**基于共享 PLM **== 共同学习这四个模块。

> Budzianowski 等人 [15] 和 Hosseini-Asl 等人 [75] 根据 **原始对话历史** 依次生成 对话状态、系统动作和最终响应。

### 8.4 Others 其他文本生成任务

在这一部分中，我们将**简要介绍其他文本生成任务**，例如==问题生成(question generation)、故事生成(story generation)和数据到文本生成(data-to-text generation)==。

#### 8.4.1 Question Generation. 问题生成

问题生成可以看作是 问答（QA）的双重任务，即根据 给定的段落和答案 **生成连贯的问题**。

> 现有的 PLM，例如 UniLM [5、36] 和 ProphetNet [150]，可以**通过 将段落和答案的串联作为输入 来用于此任务**。

此外，研究人员 ==**在不同的 QA 设置中探索**== 了这项任务。

> 例如，Huang 等人 [81] 提出了一个 **两阶段模型(a two-stage model)** 来解决 多跳问题生成(multi-hop question generation)
>
> Cao 等人 [17] 试图生成由多个句子回答的 开放式问题。
>
> 此外，Majumder 等人 [132] 提出了一个 **澄清问题生成任务(a clarification question generation task)**，以询问有关文章中缺失信息的问题，以减少歧义。

#### 8.4.2 Story Generation. 故事生成

故事（或叙事、新闻）生成需要 **利用给定的标题或假设 生成长格式的开放式文本**。基于有限的输入生成连贯且信息丰富的文本具有挑战性 [52] 。

为了丰富生成文本的内容，一些研究旨在 ==**将外部知识整合到 PLMs**== 中。

> Guan 等人 [66] 和 Mao 等人 [134] 利用 **常识知识库** 微调 PLM 以生成合理的故事。
>
> Megatron-Cntrl [192] 使用 **提取的关键字来检索知识句子**，然后选择排名靠前的句子来生成故事。
>
> 此外，为了生成连贯的长格式文本，PlotMachines 等人 [155] **从输入中提取关键字作为大纲** 来组织输出结构；
>
> Guan等人，[66]利用 **对比学习损失** 来判断原文中两句话是否连续。

#### 8.4.3 Data-to-text Generation. 数据到文本的生成 - 结构化输入数据

上述任务以 非结构化文本 作为输入，而**数据到文本生成任务 生成关于结构化输入数据 的描述性文本**，例如表格、知识图谱（KG）和抽象意义表示（abstract meaning representation, AMR）。

> 首先，一种简单直接的方法是**将 结构化表格 [29, 60] 和 KG [72, 158] 直接线性化为文本形式**作为 PLMs 的输入。
>
> ==考虑到 KG 和 AMR 的图结构==，Li 等人 [105] 和 Ribeiro 等人 [159] 使用 **图神经网络** 来学习每个节点的更好表示。
>
> 此外，为了处理结构信息，一种典型的方法是 **结合辅助训练目标**，例如预测表值 [60] 和知识图的关系 [105] (predicting the value of table [60] and the relation of knowledge graph [105])。

#### 8.4.4 Other Generation Tasks.

除了上述任务外，还有其他文本生成应用程序。 

> ColdGANs [163] 探索了 **无条件语言生成**。
>
> KG-BART [125] 研究**常识生成**，即生成由所提供的常识概念（词）组成的自然语言，可以将其视为硬约束条件生成 [52]。
>
> 此外，**文本风格迁移**旨在将文本转换为另一种风格，同时保留输入的基本语义[52]，例如情感迁移和写作风格迁移[92]。
>
> 此外，还有一些致力于**文学创作**的研究者，如诗歌[109]和抒情诗[195]。

## 9. CONCLUSION AND FUTURE DIRECTIONS 结论与展望

在本次调查中，我们概述了当前基于 PLMs 的文本生成的代表性研究工作，并期望它可以促进未来的研究。

我们首先介绍了将 PLMs 应用于文本生成时的**三个关键方面**，在此基础上，我们调查的主要内容**从输入表示学习、模型架构设计和参数优化的角度分为三个部分**。此外，我们还讨论了与**上述三个方面相关的几个重要挑战**。最后，我们回顾了**各种评估指标、开源库和常见应用程序**，以帮助从业者评估、选择和使用 PLM 进行文本生成。

尽管近年来取得了巨大的进展，但我们仍面临着几个==悬而未决的问题==，未来的几个方向有望解决这些问题。

**Controllable Generation.**  生成可控

> 使用 PLMS 生成可控文本是一个有趣的方向，但仍处于非常早期的阶段。**控制生成文本的某些属性**有很多实际用例，例如在对话系统中对患有抑郁症的患者产生积极的反应。
>
> 然而，PLMs 通常在通用语料库中进行预训练，这**很难控制生成文本的多粒度属性**（例如，情感、主题和连贯性）。
>
> Keskar等人[90] 使用 **控制样式、内容和任务特定行为的控制代码 探索文本生成**。然而，这些控制代码是预先设定的 并且 是粗粒度的。未来的工作可以探索多粒度控制并开发足够可控的 PLMs。



**Optimization Exploration.** 优化探索

> ==**微调**是将存储在 PLMs 中的**语言知识提取到下游生成任务**的主要优化方法。==
>
> 现在，**提示学习(prompt-based learning)** 已经成为一种高性能和轻量级的优化方法[119]。未来的工作可以探索更广泛的优化方法，这些方法可以结合当前方法的优点。



**Language-agnostic PLMs.**  语言无关的plms

> 目前，几乎所有的文本生成的plms都以英语为主。这些plm在处理非英语生成任务时会遇到挑战。因此，语言不可知论的plm是值得研究的
>
> 这要求我们**捕捉不同语言的 通用语言和语义特征**。一个有趣的方向是探索 如何重用现有的基于英语的plm来进行非英语语言中的文本生成。



**Ethical Concern.** 伦理问题

> 目前，plm是在从web上爬行的大规模语料库上进行预训练的，而没有进行细粒度过滤，这可能会导致伦理问题，比如生成关于用户的私有内容。因此，研究人员应尽量防止滥用plms。
>
> 此外，**plms生成的文本可能存在偏见**，这与训练数据在性别、种族和宗教等维度上的偏见相一致[14]
>
> 因此，我们应该干预plm，以防止这种偏见。对一般方法的研究是广泛的，但仍是初步的。



总之，基于plm的文本生成为这一领域的技术进步做出了巨大的贡献。然而，目前在不同的文本生成任务中的技术水平仍然远非人们的期望。需要广泛的研究努力来更好地使plm适应文本生成任务。
