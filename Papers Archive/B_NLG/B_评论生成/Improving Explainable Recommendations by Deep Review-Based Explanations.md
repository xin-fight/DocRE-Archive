# Improving Explainable Recommendations by Deep Review-Based Explanations

目前依赖于用户生成的内容来提出推荐的方法可能会遇到问题，因为众所周知的评论问题，如**噪音、稀疏性和不相关的内容。**

> **稀疏数据**的问题仍然是大多数推荐系统[9]的一个问题。当用户和项目的评分信息稀疏时，基于潜在因素的方法往往难以学习重要的信息，并可能产生不准确的结果。
>
> 其次，问题是，人工评论的很大一部分内容对推荐系统不是有用的信息。根据Chen等人[5]的说法，**用户撰写的评论质量较低**，不利于获得用户的信任和产生准确的建议。他们还认为，这些无用的评论只会增加噪音，从而损害推荐系统的能力。此外，Ghose和[10]对在线评论的主观性进行了研究，得出结论，用户更喜欢有用的引入项目客观信息的评论，而不是表达主观偏见。



在本文中，我们开发了两个基于**字符级**的深度神经网络的**个性化评论生成模型**，并通过生成符合文本感知推荐系统输入标准的高质量文本来提高推荐的准确性。



我们的实验是在来自多个领域的四个大型审查数据集上进行的。我们通过与不基于review的推荐系统和先进的review的感知推荐系统进行比较，利用了我们的方法的性能。



我们的稀疏性实验验证了我们的生成模型可以产生高质量的文本来解决稀疏性问题

对于解释的评估，定量分析显示我们生成的基于审查的解释有很好的可理解的分数，定性的案例研究证实我们可以捕捉到生成解释的关键方面。



Recent works demonstrate that deep neural network based text generation models can generate high-quality synthetic text with correct grammar and syntax [7], [12]–[14].



在本文中，我们提出了用于**高质量自然语言解释**的深度学习评论生成模型，我们**利用这些解释在评级预测和top-N项目排名推荐任务上达到了最先进的性能。**

我们应用长短时记忆（LSTM）[7]神经网络作为我们生成模型的基础，并对两个基于卷积神经网络（CNN）的推荐系统[3]，[5]进行了跨域实验。



**人写的评论内容对于可解释的推荐系统来说可能不一定有用。Chen等人[5]认为，这些无益的人写评论会增加噪音，限制了推荐的有效性。由于这些原因，我们认为精心制作的机器生成的评论可以成为比人写的评论更好的选择，以建立更好的推荐系统并向用户提供令人信服的解释。**



**因此，我们的目标是通过深度学习方法开发个性化的文本解释生成模型，生成基于评论的解释，并使用这些解释作为评论软件推荐系统的输入，以实现最先进的推荐性能。**



we start to introduce the background of deep review-based explanation generation.

> 早期的自动文本生成尝试是使用单词的聚合规则来构建句子[38]。
>
> 最近，许多使用深度学习方法的文本生成工作显示，在生成文本方面有显著改进，可以很容易地被人类理解[7]，[13]，[34]-[36]。
>
> 本质上，文本生成是一个**序列预测问题**，其中rnn学习文本中的模式，并从以前的单词（或字符）预测当前单词（或字符）
>
> >  Sutskever *et al.* [34] 是第一个引入使用**RNNs合成文本生成的模型**，而其他作品则大大扩展了它。
> >
> > Tang *et al.* [35] 将**多层感知器扩展到rnn**，可以捕获个人信息，降低内存成本
> >
> > Dong等人[13]通过**使用注意力机制**进一步发展了这个模型，并展示了卓越的文本生成性能。
> >
> > 
> >
> > GCN [12]：生成连接网络 将辅助信息与序列文本 作为循环网络的输入，以生成个性化文本。
> >
> > <hr>
> >
> >  Zhao *et al.* [14] 提出了一个**产生可读文本的生成模型来解释歌曲推荐**，这是与本文最相似的工作。
> >
> > 同样，Avinesh 等人 [18] 也提出了基于编码器-解码器序列网络的**文本摘要模型，将评论摘要作为推荐解释**。



尽管如此，这些作品在词的层面上生成文本，它们面临的一个大问题是，由于词汇量大，内存成本高。





受最近的文本生成作品7]，[12]，[13]，[35]的启发，我们通过使用深度神经技术设计了**两个字符级的个人评论生成模型**

> 字符级别的比词级别的更加严格
>
> 目的由生成评论 变为 利用产生的评论来改善推荐的精确性，并为推荐提供解释。



<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230321115357103.png" alt="image-20230629030951537" style="zoom:80%;" />

* 编码器模块的功能是将 属性(Attributes encoder)和文本(Text encoder) 编码为高维嵌入

  文本：To encode the **training review text**, 每个字符使用one-hot编码直接输入**RNN** Decoder

  属性：使用one-hot代表每个属性，放入一个隐藏层的多层感知机

  ​			为了对齐文本，我们将属性嵌入链接，并放入全连接层，**输出向量作为RNN初始向量** - 引入个性化

* RNN解码器的功能是从嵌入中 学习序列和个人属性

* 注意力机制被用来加强 输入属性和文本 之间的一致性（将两者对齐）

  我们使用注意机制来防止模型集中于不相关的信息。

* 评论生成模块可生成个性化的评论。

  我们在**生成模型中堆叠两个RNN层来生成评论，其中每一层包含512个LSTM神经元**。

  每次输出一个character，maximises the conditional probabilities *p*(*y**t* |*y**<**t**,* *a*) by a greedy search function to predict the character index *Y**t* 

  

  **如何保证输出的character组成的词是合法的**



<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230321143408027.png" alt="image-20230629030951537" style="zoom:80%;" />