# Relation-Specific Attentions over Entity Mentions for Enhanced Document-Level Relation Extraction

| <font style="background: Aquamarine">multi-mention problem - 不同的提及在不同的关系识别中起着不同的作用</font> | <font style="background: Aquamarine">plug-and-play</font> |
| :----------------------------------------------------------: | :-------------------------------------------------------: |

利用不同提及在不同关系识别中有不同作用这一特性，<font color='red'>**让实体的表示 能够特定于关系的**</font>

## 问题描述

**问题 — 多提及问题(multi-mention problem)**

> 生成**固定实体表示**的简单池化操作可能会混淆不同提及的语义，因此当**实体涉及多个有效关系**时，会降低关系分类的性能 
>
> **<font color='red'>不同的提及词在不同的关系识别中起着不同的作用</font>**



大多数文档级关系提取方法都**不区分提及级特征和实体级特征**，而**只应用简单的池化操作**将提到级特征聚合到实体级特征中。

> 这导致了一个实体的不同提及之间的不同语义被忽略
>
> **生成固定实体表示 的简单池化操作 可能会混淆不同提及的语义**，因此==当实体涉及**多个有效关系**时，会降低关系分类的性能==
>
> > <font color='red'>所以需要实体的表示 特定于关系</font>



通过t-SNE将提及嵌入降维可视化后发现：**一个实体的不同提及在语义上并不是相邻的**；**==不同的提及词在不同的关系识别中起着不同的作用==**。

## 模型改进

**根据候选关系 对不同的实体提及进行选择性关注**

> 在RSMAN中，**每个关系的基本语义首先被编码到一个原型表示中**。然后，计算一个 **特定候选关系的原型** 与 **所给实体的每个==提及表示==** 之间相关性权重（attention）
>
> 在这些注意的基础上，我们**得到了所有提及的表示的注意（加权）和，==作为实体的综合表示==**。

RSMAN使得模型在**表示实体时**能够 **关注来自不同表示空间的多个提及的信息**，表明**<font color='red'>实体的表示 对于 不同的候选关系 是灵活的 和 特定于关系的</font>**



<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230703164439951.png" alt="image-20230703164439951" style="zoom:67%;" />

> **图中展示的是 <font color='red'>对第$i$个实体下 $Q_i$个提及 的计算</font>**



==**为了让实体的表示特定于关系：**==

1. 考虑到在表示一个实体时，不同提及（mentions）与候选关系的相关性的重要性。

2. ==**a plug-in**==：对于给定一个实体，学习一个**关系特定的表示(relation-specific representation)**

   **Attentive Operations in RSMAN**：引入了注意力机制，利用**提及级别的特征来生成灵活的实体表示，以适应不同候选关系**。

   >  <font color='red'>**相当于对提及融合成实体时 引入加权计算**</font>：
   >
   > 先利用relation prototypes $p _ { r } $计算 关系r 和 实体$e_i$中每个提及$m^i_j$（有$Q_i$个提及）的 **语义相关性**（即：两个嵌入的==**相似度**==） $$s _ { i j } ^ { r } = g ( p _ { r } , m ^ { i }_j )$$ 
   >
   > * 对每个关系
   >   * 一个实体下所有提及和该关系进行计算，之后再计算attention
   >
   > 再通过==softmax利用 相关性== 得到**注意力权重attention weight**：$$\alpha _ { i j } ^ { r } = \frac { e x p ( s _ { i j } ^ { r} ) } { \sum _ { k = 1 } ^ { Q _ { k } } e x p ( s _ { i k }^r ) }$$ 
   >
   > 最后得到 ==**实体$e_i$特定于关系$r$的表示**==：$$e _ { i } ^ { r } = \sum _ { j = 1 } ^ { Q _ { i } }\alpha _ { i j }^rm^i_j$$ 



结果在DWIE数据集和DocRED数据集上进行实验：

> 该即插即用模块让模型有所提升，验证了**利用注意力的 提及级特性 来学习 ==特定于关系的 实体表示==的有效性。**
>
> RSMAN**对具有多个提及的实体更有效**，这在文档级RE的许多真实场景中更常见和更具挑战性。	
