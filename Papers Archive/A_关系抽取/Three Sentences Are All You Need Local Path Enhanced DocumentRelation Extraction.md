# **Three Sentences Are All You Need: Local Path Enhanced Document Relation Extraction**

| <font style="background: Aquamarine">Selected Paths：显式地在维护文档重要信息的同时过滤文档路径，用来覆盖 supporting evidence</font> |
| :----------------------------------------------------------: |

在本文中，我们对3个文档RE基准数据集进行了分析，发现人类注释者**经常使用少量的句子来提取文档级别的实体关系**。这促使我们去思考哪些句子对文档RE至关重要

## Do we need the entire document?

给定一对实体，起作用的可能只需要几句话，而不是整个文档，来推断它们的关系；可能没有必要阅读整个文档，因为它可能不可避免地引入不相关的信息。

* 我们发现，超过95%的例子需要不超过3句话作为支持证据，87%的例子甚至只需要2句或更少。
* ==**大多数实体关系可以用1∼3证据句来决定**==

非常少的句子（或者更准确地说，不超过3个句子）就足以使人类注释者在广泛使用的基准数据集中识别文档中几乎所有的实体关系实例。



## Which sentences are decisive?

之前工作：graph neural networks (GNNs)

> 通过聚合方案从整个上下文中收集相关信息。但从文档中选择关键证据仍然是隐性的，缺乏可解释性。



我们的初步发现表明，与将整个文档作为上下文不同，针对特定案例的选择可能更有助于帮助模型关注最相关和信息最丰富的证据。

**一种更简单的方法，可以显式地在维护文档重要信息的同时过滤文档**

它们表明头尾实体在上下文中是如何进行关联的：

> ***Consecutive Paths***
>
> > 具体来说，连续路径考虑了**头部和尾部实体在上下文中很接近**的场景：如果它们在3个连续的句子内，我们将这些句子视为一条路径。且将在一个句内的情况视为连续路径的一种类型
> >
> > 一对实体可以对应于多个连续的路径，因为它们可以被多次提及。
>
> ***Multi-Hop Paths***
>
> > Multi-Hop Paths对应于遥远句子中的实体对，但可以通过 在不同句子中与头实体和尾实体同时出现的 **其他实体进行桥接**。
> >
> > 由于大部分关系只需要3句话就可得到，因此**只有1个或2个桥接实体。**
> >
> > 对于具有不同桥接实体列表的特定对，可以有几个多跳路径。	
>
> ***Default Paths***
>
> > **当上述两种规则都不适用时，我们收集所有的句子对**，其中一个包含头部实体，另一个包含尾部实体作为默认路径。
> >
> > Formally, let $\{S_{h_1}, ..., S_{h_p}\}$ and $\{S_{t_1}, ..., S_{t_q}\}$  denote the sets of sentences that contain the head entity $e_h$ and the tail entity $e_t$ (包含头尾实体的句子集), respectively. 
> >
> > For this entity pair, we will **have $p × q$ Default Paths**  $\{S_{h_1}, ..., S_{t_p}\}, ..., \{S_{h_p}, ..., S_{t_q}\}$ .
>
> 我们发现，高达87.5%的支持性证据可以被我们的启发式选择的路径完全覆盖；
>
> > **路径是用来覆盖 supporting evidence**
> >
> > ==**supporting evidence**==【关系实例的支持证据是指：所有可以用来决定实体对之间是否存在这种关系的句子，由人类注释者标记（Yao et al.，2019）】
>
> 我们的**直接和可解释的规则可以作为从文件中选择支持性证据的有效代理**
>
> <img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230530170224222.png" alt="image-20230530170224222" style="zoom: 80%;" />



## Comparing with Annotated Evidence - 如何衡量选择的句子

gold annotation作为所有相关证据的集合，而我们提取的每个路径都代表一个可能的以及最小的句子集。理想情况下，如果路径集足够了，那么实体对之间的所有连接句子都应该被成功捕获。换句话说，它们（ all connecting sentences between the entity pair）将通过我们的路径集中的各种路径来呈现

因此，==**路径的 并集（the union of paths）有望成为支持证据的超集**==

> $\therefore$ 我们使用==**支持证据的覆盖范围来衡量我们的路径集的充分性**==，这代表了支持证据完全被我们的路径的并集所覆盖的实例的百分比。
>
> 同时，**路径的总数（#Path）和路径的并集大小（#Sent）也应保持在一个较低的标准**，以避免冗余。

<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230530170452465.png" alt="image-20230530170452465" style="zoom:67%;" />

> C+M+D不能涵盖所有实例的主要原因是DocRED中注释的支持证据包含了所有相关的句子，而C+M+D只找到一个足够的集合来识别关系。
>
> 我们的方法可以过滤掉多达2/3的原始文本；**为gold supporting evidence形成了一个充分和非冗余的估计，极大地减轻了无关信息的负面影响。**



## Experiments - 将提取的paths输入到模型中

**每条路径对应于头和尾实体的一个可能的连接，所以我们独立地预测与每条路径的关系，并在之后汇总结果。**

> 对于每一条路径c，我们将其中的所有句子连接为一个片段[w1 c，...，wc m]，其中句子的顺序与原始文档中相同
>
> ==对每个路径计算关系的概率，在获得给定实体对之间的每条路径的预测后，我们选择最有可能的预测来聚合预测结果==

<img src="https://cdn.jsdelivr.net/gh/xin-fight/note_image@main/img/image-20230530212125097.png" alt="image-20230530212125097" style="zoom:67%;" />

虽然基于图的模型已经显示出了以自适应的方式关注重要信息的优秀能力，但明确地从文档中进行选择比完全依赖基于图的模型更有帮助



## Discussion - 这种做法在跨学科的观点上可行度

从语言学角度来看

> 讨论现象的一个可能原因是，**表面上看起来相距较远的关系在其语言形式上并不那么困难**。Stevenson（2006）提到，大多数句间关系实例实际上是由于共指（回指表达式或替代描述 [anaphoric expressions or alternative descriptions)]）。**在这些情况下，关系可以被认为完全在一句话中描述**，但是头部或尾部实体间接地被引用。考虑到回指表达式很可能出现在与候选提及相关的周围句子中（Chowdhury和Zweigenbaum，2013），这些发现与我们的观察完全一致，即**连续的路径可以支持超过70％的关系实例，并为“三句话现象”提供了证据**。
>
> 这段描述指出，讨论现象的一个可能原因是关系的语言形式使得看似相距较远的关系并不那么困难。许多句间关系实际上是由于共指，即通过回指表达式或替代描述来间接引用头部或尾部实体。考虑到回指表达式可能出现在与候选提及相关的周围句子中，这些发现与之前的观察结果一致，即连续的路径可以支持超过70％的关系实例，并为三句话现象提供了证据。换句话说，**虽然某些关系在语法结构上可能跨越多个句子，但实际上可以通过共指关系在一个句子中进行描述。这进一步支持了连续路径在关系推断中的重要性。**

认知角度从认知角度来看

> RE任务在有限的实体和上下文范围内进行定义，这与人脑的本质相吻合，可能是另一个可能的解释。人们普遍认为工作记忆（Working Memory，WM）（Baddeley，1992）在推理任务中起着存储和操作信息的关键作用（Barreyro等，2012），但是WM中单独信息块的容量通常限制在4个（Cowan，2001）个。由于我们需要记住推理链中的所有单独实体及其关系，因此**我们自然而然地倾向于在有限的句子中描述关系**，因为使用更多的句子来描述关系可能会使我们的WM超过其容量。Daneman和Carpenter（1980）表明，如果任务需要过多信息超过受试者WM容量的限制，完成阅读任务的成功率会急剧下降。因此，**由于数据集是从自然语言构建的，数据中的三句话现象可能是我们（无意识地）遵循的一种常见模式，以实现相互理解**。